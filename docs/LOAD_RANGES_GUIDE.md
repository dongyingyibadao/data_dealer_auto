# ğŸ“‹ Load Ranges ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`--load-ranges` å‚æ•°å…è®¸æ‚¨åŠ è½½ä¹‹å‰ä¿å­˜çš„å¸§èŒƒå›´åˆ†æç»“æœï¼Œè·³è¿‡è€—æ—¶çš„å¤¹çˆªæ£€æµ‹è¿‡ç¨‹ï¼Œç›´æ¥è¿›è¡Œæ•°æ®è½¬æ¢ã€‚è¿™åœ¨éœ€è¦å¤šæ¬¡å¤„ç†åŒä¸€æ•°æ®é›†æˆ–è°ƒæ•´å¤„ç†å‚æ•°æ—¶éå¸¸æœ‰ç”¨ã€‚

## ğŸ¯ é€‚ç”¨åœºæ™¯

### åœºæ™¯1ï¼šåˆ†ç¦»åˆ†æå’Œè½¬æ¢æ­¥éª¤

å½“æ‚¨æƒ³å…ˆå¿«é€Ÿåˆ†ææ•°æ®é›†ï¼Œç¡®è®¤æ£€æµ‹ç»“æœåå†è¿›è¡Œå®Œæ•´è½¬æ¢ï¼š

```bash
# ç¬¬ä¸€æ­¥ï¼šä»…åˆ†æï¼Œç”Ÿæˆ frame_ranges_info.json
python auto_cut_dataset.py \
    --dataset-path /path/to/dataset \
    --end-idx 10000 \
    --skip-cutting

# ç¬¬äºŒæ­¥ï¼šæŸ¥çœ‹åˆ†æç»“æœ
cat cut_dataset/frame_ranges_info.json | python -m json.tool | head -50

# ç¬¬ä¸‰æ­¥ï¼šç¡®è®¤æ— è¯¯åï¼Œä½¿ç”¨åˆ†æç»“æœè¿›è¡Œè½¬æ¢
python auto_cut_dataset.py \
    --dataset-path /path/to/dataset \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 100
```

**ä¼˜åŠ¿**ï¼š
- âœ… é¿å…é‡å¤åˆ†æï¼ŒèŠ‚çœæ—¶é—´ï¼ˆåˆ†æå¯èƒ½éœ€è¦æ•°å°æ—¶ï¼‰
- âœ… å¯ä»¥å…ˆéªŒè¯æ£€æµ‹ç»“æœçš„å‡†ç¡®æ€§
- âœ… çµæ´»è°ƒæ•´è½¬æ¢å‚æ•°è€Œæ— éœ€é‡æ–°åˆ†æ

### åœºæ™¯2ï¼šè°ƒæ•´å¤„ç†å‚æ•°

ä½¿ç”¨ç›¸åŒçš„æ£€æµ‹ç»“æœï¼Œä½†æ”¹å˜å…¶ä»–å‚æ•°ï¼š

```bash
# ç¬¬ä¸€æ¬¡ï¼šç”Ÿæˆ100ä¸ªepisodes
python auto_cut_dataset.py \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 100 \
    --output-dir ./cut_dataset_v1

# ç¬¬äºŒæ¬¡ï¼šç”Ÿæˆ500ä¸ªepisodesï¼ˆä¸åŒè¾“å‡ºç›®å½•ï¼‰
python auto_cut_dataset.py \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 500 \
    --output-dir ./cut_dataset_v2

# ç¬¬ä¸‰æ¬¡ï¼šä½¿ç”¨ä¸åŒçš„LLMç”Ÿæˆä»»åŠ¡æè¿°
python auto_cut_dataset.py \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 100 \
    --llm-provider gpt \
    --llm-api-key YOUR_KEY \
    --output-dir ./cut_dataset_v3
```

**ä¼˜åŠ¿**ï¼š
- âœ… å¿«é€Ÿç”Ÿæˆå¤šä¸ªç‰ˆæœ¬çš„æ•°æ®é›†
- âœ… æµ‹è¯•ä¸åŒçš„LLMæä¾›å•†
- âœ… è°ƒæ•´episodeæ•°é‡è€Œæ— éœ€é‡æ–°æ£€æµ‹

### åœºæ™¯3ï¼šæ‰‹åŠ¨ä¿®æ­£æ£€æµ‹ç»“æœ

å½“è‡ªåŠ¨æ£€æµ‹å‡ºç°é”™è¯¯æ—¶ï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨ç¼–è¾‘ `frame_ranges_info.json`ï¼š

```bash
# ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆåˆå§‹åˆ†æç»“æœ
python auto_cut_dataset.py \
    --dataset-path /path/to/dataset \
    --skip-cutting

# ç¬¬äºŒæ­¥ï¼šæ‰‹åŠ¨ç¼–è¾‘ JSON æ–‡ä»¶
vim cut_dataset/frame_ranges_info.json
# æˆ–ä½¿ç”¨å…¶ä»–ç¼–è¾‘å™¨ä¿®æ­£é”™è¯¯çš„æ£€æµ‹ç»“æœ

# ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨ä¿®æ­£åçš„ç»“æœè¿›è¡Œè½¬æ¢
python auto_cut_dataset.py \
    --dataset-path /path/to/dataset \
    --load-ranges cut_dataset/frame_ranges_info.json
```

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨æ§åˆ¶æœ€ç»ˆä½¿ç”¨çš„å¸§èŒƒå›´
- âœ… ä¿®æ­£è¯¯æ£€æˆ–æ¼æ£€çš„æ“ä½œ
- âœ… æ·»åŠ è‡ªå®šä¹‰çš„ä»»åŠ¡æè¿°

### åœºæ™¯4ï¼šå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†

å¯¹äºè¶…å¤§æ•°æ®é›†ï¼Œåˆ†ç¦»åˆ†æå’Œè½¬æ¢å¯ä»¥æ›´å¥½åœ°ç®¡ç†èµ„æºï¼š

```bash
# ç¬¬ä¸€æ­¥ï¼šåœ¨å†…å­˜è¾ƒå°çš„æœºå™¨ä¸Šè¿›è¡Œåˆ†æï¼ˆä»…éœ€å°‘é‡å†…å­˜ï¼‰
python auto_cut_dataset.py \
    --dataset-path /path/to/large/dataset \
    --skip-cutting

# ç¬¬äºŒæ­¥ï¼šå°† frame_ranges_info.json å¤åˆ¶åˆ°é«˜æ€§èƒ½æœåŠ¡å™¨

# ç¬¬ä¸‰æ­¥ï¼šåœ¨é«˜æ€§èƒ½æœåŠ¡å™¨ä¸Šè¿›è¡Œè½¬æ¢ï¼ˆéœ€è¦å¤§é‡å†…å­˜å’Œç£ç›˜ï¼‰
python auto_cut_dataset.py \
    --dataset-path /path/to/large/dataset \
    --load-ranges frame_ranges_info.json \
    --batch-size 100 \
    --output-dir /fast/ssd/output
```

**ä¼˜åŠ¿**ï¼š
- âœ… åˆ†æå’Œè½¬æ¢å¯åœ¨ä¸åŒæœºå™¨ä¸Šæ‰§è¡Œ
- âœ… æ›´å¥½åœ°åˆ©ç”¨ç¡¬ä»¶èµ„æº
- âœ… åˆ†æç»“æœå¯ä»¥å¤‡ä»½å’Œå…±äº«

## ğŸ“„ frame_ranges_info.json æ–‡ä»¶æ ¼å¼

### å®Œæ•´ç»“æ„

```json
{
  "total_ranges": 100,
  "pick_count": 45,
  "place_count": 55,
  "frame_ranges": [
    {
      "id": 0,
      "keyframe_index": 100727,
      "action_type": "place",
      "frame_start": 100697,
      "frame_end": 100757,
      "num_frames": 60,
      "original_task": "put both moka pots on the stove",
      "new_task": "put the moka pot on the stove",
      "episode_index": 376
    },
    {
      "id": 1,
      "keyframe_index": 102345,
      "action_type": "pick",
      "frame_start": 102315,
      "frame_end": 102375,
      "num_frames": 60,
      "original_task": "pick up the cup",
      "new_task": "pick up the cup from the table",
      "episode_index": 380
    }
  ]
}
```

### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `total_ranges` | int | æ£€æµ‹åˆ°çš„æ€»æ“ä½œæ•° |
| `pick_count` | int | Pick æ“ä½œæ•°é‡ |
| `place_count` | int | Place æ“ä½œæ•°é‡ |
| `frame_ranges` | array | æ‰€æœ‰æ£€æµ‹åˆ°çš„æ“ä½œåˆ—è¡¨ |

### å•ä¸ªæ“ä½œçš„å­—æ®µ

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `id` | int | æ“ä½œçš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆä»0å¼€å§‹ï¼‰ |
| `keyframe_index` | int | å…³é”®å¸§åœ¨åŸå§‹æ•°æ®é›†ä¸­çš„ç´¢å¼• |
| `action_type` | string | æ“ä½œç±»å‹ï¼š"pick" æˆ– "place" |
| `frame_start` | int | æå–çš„èµ·å§‹å¸§ç´¢å¼• |
| `frame_end` | int | æå–çš„ç»“æŸå¸§ç´¢å¼•ï¼ˆä¸åŒ…å«ï¼‰ |
| `num_frames` | int | æå–çš„æ€»å¸§æ•° |
| `original_task` | string | åŸå§‹æ•°æ®é›†ä¸­çš„ä»»åŠ¡æè¿° |
| `new_task` | string | ç”Ÿæˆçš„æ–°ä»»åŠ¡æè¿° |
| `episode_index` | int | åŸå§‹æ•°æ®é›†ä¸­çš„ episode ç´¢å¼• |

## ğŸ› ï¸ å·¥ä½œåŸç†

### æ­£å¸¸æµç¨‹ï¼ˆä¸ä½¿ç”¨ --load-rangesï¼‰

```
1. åŠ è½½æ•°æ®é›†
   â†“
2. å¤¹çˆªçŠ¶æ€æ£€æµ‹ï¼ˆè€—æ—¶â±ï¸ï¼‰
   - éå†æ‰€æœ‰å¸§
   - æ£€æµ‹å¤¹çˆªçŠ¶æ€å˜åŒ–
   - æå–å¸§èŒƒå›´
   â†“
3. ä»»åŠ¡æè¿°ç”Ÿæˆï¼ˆå¯é€‰ï¼Œè€—æ—¶â±ï¸ï¼‰
   - ä½¿ç”¨ LLM ç”Ÿæˆæè¿°
   â†“
4. ä¿å­˜åˆ†æç»“æœ
   - è¾“å‡º frame_ranges_info.json
   â†“
5. æ•°æ®è½¬æ¢ï¼ˆè€—æ—¶â±ï¸ï¼‰
   - æå–å¸§æ•°æ®
   - è½¬æ¢ä¸º LeRobot æ ¼å¼
```

### ä½¿ç”¨ --load-ranges çš„æµç¨‹

```
1. åŠ è½½ frame_ranges_info.json
   â†“
2. [è·³è¿‡] å¤¹çˆªçŠ¶æ€æ£€æµ‹ âœ… èŠ‚çœæ—¶é—´
   â†“
3. [å¯é€‰] ä»»åŠ¡æè¿°ç”Ÿæˆ
   - å¦‚æœ JSON ä¸­å·²æœ‰æè¿°ï¼Œå¯ç›´æ¥ä½¿ç”¨
   - ä¹Ÿå¯ä»¥ç”¨ --llm-provider é‡æ–°ç”Ÿæˆ
   â†“
4. æ•°æ®è½¬æ¢
   - æ ¹æ® JSON ä¸­çš„å¸§èŒƒå›´æå–æ•°æ®
   - è½¬æ¢ä¸º LeRobot æ ¼å¼
```

**æ—¶é—´å¯¹æ¯”ç¤ºä¾‹**ï¼š
- å®Œæ•´æµç¨‹ï¼ˆ10,000å¸§ï¼‰ï¼šçº¦ 10-15 åˆ†é’Ÿ
- ä½¿ç”¨ --load-rangesï¼šçº¦ 2-3 åˆ†é’Ÿ
- **èŠ‚çœæ—¶é—´**ï¼š70-80%

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºæœ¬ç”¨æ³•

```bash
# åˆ†æé˜¶æ®µ
python auto_cut_dataset.py \
    --dataset-path /data/robot_dataset \
    --end-idx 50000 \
    --skip-cutting

# è½¬æ¢é˜¶æ®µ
python auto_cut_dataset.py \
    --dataset-path /data/robot_dataset \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 200
```

### ç¤ºä¾‹2ï¼šä½¿ç”¨ä¸åŒçš„ LLM

```bash
# ä½¿ç”¨æœ¬åœ°æ–¹æ³•ç”Ÿæˆåˆå§‹æè¿°
python auto_cut_dataset.py \
    --dataset-path /data/robot_dataset \
    --skip-cutting

# ä½¿ç”¨ GPT é‡æ–°ç”Ÿæˆæ›´å¥½çš„æè¿°
python auto_cut_dataset.py \
    --dataset-path /data/robot_dataset \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --llm-provider gpt \
    --llm-api-key YOUR_KEY \
    --llm-api-base https://gpt.yunstorm.com/ \
    --llm-model gpt-4o
```

### ç¤ºä¾‹3ï¼šç”Ÿæˆå¤šä¸ªç‰ˆæœ¬

```bash
# ç”Ÿæˆæµ‹è¯•ç‰ˆï¼ˆå°è§„æ¨¡ï¼‰
python auto_cut_dataset.py \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 50 \
    --output-dir ./test_dataset

# ç”Ÿæˆè®­ç»ƒç‰ˆï¼ˆä¸­è§„æ¨¡ï¼‰
python auto_cut_dataset.py \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --max-episodes 500 \
    --output-dir ./train_dataset

# ç”Ÿæˆå®Œæ•´ç‰ˆï¼ˆå¤§è§„æ¨¡ï¼‰
python auto_cut_dataset.py \
    --load-ranges cut_dataset/frame_ranges_info.json \
    --output-dir ./full_dataset
```

### ç¤ºä¾‹4ï¼šè·¨æœºå™¨å¤„ç†

```bash
# åœ¨æœºå™¨ Aï¼ˆåˆ†ææœåŠ¡å™¨ï¼‰
python auto_cut_dataset.py \
    --dataset-path /data/source \
    --skip-cutting

# å¤åˆ¶æ–‡ä»¶åˆ°æœºå™¨ B
scp cut_dataset/frame_ranges_info.json user@machineB:/tmp/

# åœ¨æœºå™¨ Bï¼ˆé«˜æ€§èƒ½æœåŠ¡å™¨ï¼‰
python auto_cut_dataset.py \
    --dataset-path /data/source \
    --load-ranges /tmp/frame_ranges_info.json \
    --batch-size 100 \
    --output-dir /fast/storage/dataset
```

## âœï¸ æ‰‹åŠ¨ç¼–è¾‘ JSON

### åˆ é™¤ä¸éœ€è¦çš„æ“ä½œ

å¦‚æœåªæƒ³ä¿ç•™ç‰¹å®šç±»å‹çš„æ“ä½œï¼š

```python
import json

# è¯»å–
with open('cut_dataset/frame_ranges_info.json', 'r') as f:
    data = json.load(f)

# åªä¿ç•™ pick æ“ä½œ
data['frame_ranges'] = [r for r in data['frame_ranges'] if r['action_type'] == 'pick']
data['total_ranges'] = len(data['frame_ranges'])
data['place_count'] = 0

# ä¿å­˜
with open('cut_dataset/frame_ranges_pick_only.json', 'w') as f:
    json.dump(data, f, indent=2)
```

### ä¿®æ”¹ä»»åŠ¡æè¿°

```python
import json

with open('cut_dataset/frame_ranges_info.json', 'r') as f:
    data = json.load(f)

# æ‰¹é‡ä¿®æ”¹ä»»åŠ¡æè¿°
for r in data['frame_ranges']:
    if 'moka pot' in r['original_task']:
        r['new_task'] = 'manipulate the coffee maker'

with open('cut_dataset/frame_ranges_modified.json', 'w') as f:
    json.dump(data, f, indent=2)
```

### åˆå¹¶å¤šä¸ªåˆ†æç»“æœ

```python
import json

# è¯»å–å¤šä¸ªæ–‡ä»¶
with open('dataset1/frame_ranges_info.json', 'r') as f:
    data1 = json.load(f)
with open('dataset2/frame_ranges_info.json', 'r') as f:
    data2 = json.load(f)

# åˆå¹¶
merged = {
    'total_ranges': data1['total_ranges'] + data2['total_ranges'],
    'pick_count': data1['pick_count'] + data2['pick_count'],
    'place_count': data1['place_count'] + data2['place_count'],
    'frame_ranges': data1['frame_ranges'] + data2['frame_ranges']
}

# é‡æ–°ç¼–å·
for i, r in enumerate(merged['frame_ranges']):
    r['id'] = i

# ä¿å­˜
with open('merged_ranges.json', 'w') as f:
    json.dump(merged, f, indent=2)
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ•°æ®é›†è·¯å¾„ä¸€è‡´æ€§

ä½¿ç”¨ `--load-ranges` æ—¶ï¼Œå¿…é¡»æŒ‡å®šä¸åˆ†ææ—¶ç›¸åŒçš„æ•°æ®é›†è·¯å¾„ï¼š

```bash
# âŒ é”™è¯¯ï¼šæ•°æ®é›†è·¯å¾„ä¸åŒ
python auto_cut_dataset.py --skip-cutting --dataset-path /data/v1
python auto_cut_dataset.py --load-ranges cut_dataset/frame_ranges_info.json --dataset-path /data/v2

# âœ… æ­£ç¡®ï¼šä½¿ç”¨ç›¸åŒè·¯å¾„
python auto_cut_dataset.py --skip-cutting --dataset-path /data/v1
python auto_cut_dataset.py --load-ranges cut_dataset/frame_ranges_info.json --dataset-path /data/v1
```

### 2. JSON æ–‡ä»¶å®Œæ•´æ€§

ç¡®ä¿ JSON æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼š

```bash
# éªŒè¯ JSON æ ¼å¼
python -m json.tool cut_dataset/frame_ranges_info.json > /dev/null
echo $?  # åº”è¯¥è¿”å› 0
```

### 3. ç´¢å¼•èŒƒå›´æœ‰æ•ˆæ€§

å¦‚æœæ•°æ®é›†å‘ç”Ÿå˜åŒ–ï¼Œframe_ranges_info.json ä¸­çš„ç´¢å¼•å¯èƒ½æ— æ•ˆï¼š

```python
# æ£€æŸ¥ç´¢å¼•æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
import json
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset

dataset = LeRobotDataset("your-dataset")
with open('cut_dataset/frame_ranges_info.json', 'r') as f:
    data = json.load(f)

max_index = max(r['frame_end'] for r in data['frame_ranges'])
if max_index > len(dataset):
    print(f"âš ï¸ è­¦å‘Šï¼šç´¢å¼•è¶…å‡ºèŒƒå›´ ({max_index} > {len(dataset)})")
```

### 4. ä¸å…¶ä»–å‚æ•°çš„å…¼å®¹æ€§

æŸäº›å‚æ•°åœ¨ä½¿ç”¨ `--load-ranges` æ—¶ä¼šè¢«å¿½ç•¥ï¼š

| å‚æ•° | æ˜¯å¦ç”Ÿæ•ˆ | è¯´æ˜ |
|------|---------|------|
| `--before-frames` | âŒ | å¸§èŒƒå›´å·²åœ¨ JSON ä¸­å®šä¹‰ |
| `--after-frames` | âŒ | å¸§èŒƒå›´å·²åœ¨ JSON ä¸­å®šä¹‰ |
| `--start-idx` | âŒ | ç´¢å¼•å·²åœ¨ JSON ä¸­å®šä¹‰ |
| `--end-idx` | âŒ | ç´¢å¼•å·²åœ¨ JSON ä¸­å®šä¹‰ |
| `--max-episodes` | âœ… | å¯ä»¥é™åˆ¶è¾“å‡ºæ•°é‡ |
| `--llm-provider` | âœ… | å¯ä»¥é‡æ–°ç”Ÿæˆä»»åŠ¡æè¿° |
| `--output-dir` | âœ… | æŒ‡å®šè¾“å‡ºä½ç½® |
| `--batch-size` | âœ… | æ§åˆ¶å†…å­˜ä½¿ç”¨ |

## ğŸ” æ•…éšœæ’é™¤

### é”™è¯¯ï¼šFileNotFoundError

```bash
FileNotFoundError: [Errno 2] No such file or directory: 'cut_dataset/frame_ranges_info.json'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®ä¿å…ˆè¿è¡Œè¿‡åˆ†ææ­¥éª¤ï¼ˆä½¿ç”¨ `--skip-cutting`ï¼‰

### é”™è¯¯ï¼šJSONDecodeError

```bash
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ JSON æ–‡ä»¶æ˜¯å¦æŸå
- ä½¿ç”¨ `python -m json.tool` éªŒè¯æ ¼å¼
- é‡æ–°ç”Ÿæˆ frame_ranges_info.json

### é”™è¯¯ï¼šKeyError

```bash
KeyError: 'frame_ranges'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- JSON æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘å¿…éœ€å­—æ®µ
- ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„æ ¼å¼ç¤ºä¾‹é‡æ–°ç”Ÿæˆ

### ç´¢å¼•è¶…å‡ºèŒƒå›´

```bash
IndexError: index 100000 is out of bounds for axis 0 with size 50000
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- frame_ranges_info.json ä¸å½“å‰æ•°æ®é›†ä¸åŒ¹é…
- ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®é›†
- é‡æ–°ç”Ÿæˆåˆ†æç»“æœ

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### æµ‹è¯•åœºæ™¯ï¼šå¤„ç† 100,000 å¸§æ•°æ®

| æ–¹æ³• | åˆ†ææ—¶é—´ | è½¬æ¢æ—¶é—´ | æ€»æ—¶é—´ | å¤‡æ³¨ |
|------|---------|---------|--------|------|
| å®Œæ•´æµç¨‹ | 15 åˆ†é’Ÿ | 8 åˆ†é’Ÿ | 23 åˆ†é’Ÿ | é¦–æ¬¡å¤„ç† |
| ä½¿ç”¨ --load-ranges | 0 åˆ†é’Ÿ | 8 åˆ†é’Ÿ | 8 åˆ†é’Ÿ | èŠ‚çœ 65% |
| ä½¿ç”¨ --load-ranges + ä¸åŒ LLM | 0 åˆ†é’Ÿ | 12 åˆ†é’Ÿ | 12 åˆ†é’Ÿ | èŠ‚çœ 48% |

### å†…å­˜ä½¿ç”¨

| æ–¹æ³• | å³°å€¼å†…å­˜ |
|------|---------|
| å®Œæ•´æµç¨‹ | ~12 GB |
| ä½¿ç”¨ --load-ranges | ~8 GB |

## ğŸ“ æœ€ä½³å®è·µ

1. **å§‹ç»ˆä¿å­˜åˆ†æç»“æœ**
   ```bash
   # å³ä½¿ä¸ä½¿ç”¨ --skip-cuttingï¼Œä¹Ÿä¼šè‡ªåŠ¨ä¿å­˜ frame_ranges_info.json
   python auto_cut_dataset.py --end-idx 10000
   # ç»“æœä¿å­˜åœ¨ cut_dataset/frame_ranges_info.json
   ```

2. **å¤‡ä»½é‡è¦çš„åˆ†æç»“æœ**
   ```bash
   cp cut_dataset/frame_ranges_info.json frame_ranges_backup_$(date +%Y%m%d).json
   ```

3. **ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç† JSON æ–‡ä»¶**
   ```bash
   git add cut_dataset/frame_ranges_info.json
   git commit -m "Add frame ranges analysis for dataset v1.0"
   ```

4. **ä¸ºä¸åŒé…ç½®åˆ›å»ºä¸åŒçš„ JSON æ–‡ä»¶**
   ```bash
   # ä¸åŒçš„å¸§èŒƒå›´é…ç½®
   python auto_cut_dataset.py --before-frames 20 --after-frames 20 --skip-cutting
   mv cut_dataset/frame_ranges_info.json frame_ranges_40frames.json
   
   python auto_cut_dataset.py --before-frames 30 --after-frames 30 --skip-cutting
   mv cut_dataset/frame_ranges_info.json frame_ranges_60frames.json
   ```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [USAGE_GUIDE.md](./USAGE_GUIDE.md) - å®Œæ•´ä½¿ç”¨æŒ‡å—
- [CHECKPOINT_GUIDE.md](./CHECKPOINT_GUIDE.md) - æ–­ç‚¹ç»­ä¼ æŒ‡å—
- [PROMPT_CUSTOMIZATION_GUIDE.md](./PROMPT_CUSTOMIZATION_GUIDE.md) - ä»»åŠ¡æè¿°å®šåˆ¶

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** è¿è¡Œ `python auto_cut_dataset.py --help` æŸ¥çœ‹æ‰€æœ‰å‚æ•°
