"""
æ•°æ®é›†è£å‰ªå’ŒLeRobotæ ¼å¼è½¬æ¢
"""
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import json
from datetime import datetime
import copy
from PIL import Image
import io


class DatasetCutter:
    """
    æ•°æ®é›†è£å‰ªå™¨ - æå–æŒ‡å®šèŒƒå›´çš„å¸§å¹¶æ”¯æŒä¸¤ç§ä¿å­˜æ¨¡å¼ï¼š
    1. å›¾ç‰‡æ¨¡å¼ï¼šä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶ï¼ˆæ–¹ä¾¿æ£€æŸ¥ï¼‰
    2. LeRobotæ¨¡å¼ï¼šä¿å­˜ä¸ºParquetæ ¼å¼ï¼ˆæ–¹ä¾¿è®­ç»ƒï¼‰
    """
    
    def __init__(self, output_dir: str = None, save_mode: str = 'lerobot'):
        """
        åˆå§‹åŒ–æ•°æ®é›†è£å‰ªå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            save_mode: ä¿å­˜æ¨¡å¼ 'image' æˆ– 'lerobot' æˆ– 'both'
        """
        self.output_dir = Path(output_dir) if output_dir else Path('./cut_dataset')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.save_mode = save_mode
        self.episodes_data = []
        self.metadata_buffer = []
    
    def extract_frames(self, 
                      dataset,
                      frame_ranges: List[Dict],
                      verbose: bool = True) -> List[Dict]:
        """
        ä»æ•°æ®é›†ä¸­æå–æŒ‡å®šèŒƒå›´çš„å¸§
        
        Args:
            dataset: LeRobotæ•°æ®é›†
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        Returns:
            æå–çš„æ•°æ®åˆ—è¡¨
        """
        extracted_data = []
        
        if verbose:
            print(f"ğŸ“¥ å¼€å§‹æå–å¸§æ•°æ®...")
        
        for range_idx, frame_range in enumerate(frame_ranges):
            if verbose and range_idx % 10 == 0:
                print(f"  å¤„ç†èŒƒå›´ {range_idx}/{len(frame_ranges)}")
            
            start_idx = frame_range['frame_start']
            end_idx = frame_range['frame_end']
            
            for frame_idx in range(start_idx, end_idx):
                try:
                    item = dataset[frame_idx]
                    
                    # å¤åˆ¶æ•°æ®é¡¹
                    new_item = copy.deepcopy({k: v for k, v in item.items() 
                                             if k in ['observation.images.image',
                                                     'observation.images.image2',
                                                     'observation.state',
                                                     'action',
                                                     'timestamp',
                                                     'frame_index',
                                                     'episode_index',
                                                     'task_index']})
                    
                    # æ·»åŠ å…ƒæ•°æ®
                    new_item['original_index'] = frame_idx
                    new_item['cut_range_id'] = range_idx
                    new_item['original_task'] = frame_range['task']
                    new_item['new_task'] = frame_range.get('new_task', frame_range['task'])
                    new_item['action_type'] = frame_range['action_type']
                    new_item['keyframe_index'] = frame_range['keyframe_index']
                    
                    extracted_data.append(new_item)
                
                except Exception as e:
                    if verbose:
                        print(f"âš ï¸  æå–ç´¢å¼• {frame_idx} æ—¶å‡ºé”™: {e}")
                    continue
        
        if verbose:
            print(f"âœ“ æå–å®Œæˆï¼Œå…± {len(extracted_data)} å¸§")
        
        return extracted_data
    
    def organize_by_episode(self, 
                           extracted_data: List[Dict]) -> Dict[int, List[Dict]]:
        """
        æŒ‰episodeç»„ç»‡æå–çš„æ•°æ®
        
        Args:
            extracted_data: æå–çš„æ•°æ®åˆ—è¡¨
            
        Returns:
            æŒ‰episode_indexç»„ç»‡çš„æ•°æ®å­—å…¸
        """
        episodes = {}
        
        for item in extracted_data:
            cut_range_id = item['cut_range_id']
            if cut_range_id not in episodes:
                episodes[cut_range_id] = {
                    'frames': [],
                    'metadata': {
                        'cut_range_id': cut_range_id,
                        'action_type': item['action_type'],
                        'original_task': item['original_task'],
                        'new_task': item['new_task'],
                        'episode_index': item.get('episode_index', -1),
                        'task_index': item.get('task_index', -1),
                        'keyframe_index': item['keyframe_index']
                    }
                }
            
            episodes[cut_range_id]['frames'].append(item)
        
        return episodes
    
    def save_as_image_format(self,
                           episodes_data: Dict[int, Dict],
                           frame_ranges: List[Dict],
                           max_episodes: Optional[int] = None) -> Path:
        """
        å°†æ•°æ®ä¿å­˜ä¸ºå›¾ç‰‡æ ¼å¼ï¼ˆç±»ä¼¼data_dealerï¼‰
        
        Args:
            episodes_data: æŒ‰episodeç»„ç»‡çš„æ•°æ®
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®ä¸ºå›¾ç‰‡æ ¼å¼...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        images_dir = self.output_dir / 'images'
        images_dir.mkdir(parents=True, exist_ok=True)
        
        episodes_info = []
        
        for cut_range_id, episode_data in sorted(episodes_data.items()):
            if max_episodes and len(episodes_info) >= max_episodes:
                break
            
            frames = episode_data['frames']
            metadata = episode_data['metadata']
            
            episode_idx = len(episodes_info)
            episode_dir = images_dir / f"episode_{episode_idx:04d}"
            episode_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜æ¯ä¸€å¸§çš„å›¾åƒ
            frame_files = []
            for frame_idx, frame_data in enumerate(frames):
                # ä¿å­˜ä¸»æ‘„åƒå¤´å›¾åƒ
                img1 = self._tensor_to_image(frame_data['observation.images.image'])
                img1_path = episode_dir / f"frame_cam1_{frame_idx:04d}.jpg"
                img1.save(img1_path, quality=95)
                
                # ä¿å­˜ç¬¬äºŒæ‘„åƒå¤´å›¾åƒ
                img2 = self._tensor_to_image(frame_data['observation.images.image2'])
                img2_path = episode_dir / f"frame_cam2_{frame_idx:04d}.jpg"
                img2.save(img2_path, quality=95)
                
                frame_files.append({
                    'frame_idx': frame_idx,
                    'cam1': str(img1_path.relative_to(self.output_dir)),
                    'cam2': str(img2_path.relative_to(self.output_dir)),
                    'action': frame_data['action'].cpu().numpy().tolist() if hasattr(frame_data['action'], 'cpu') else frame_data['action'].tolist(),
                    'state': frame_data['observation.state'].cpu().numpy().tolist() if hasattr(frame_data['observation.state'], 'cpu') else frame_data['observation.state'].tolist(),
                })
            
            episode_info = {
                'episode_idx': episode_idx,
                'cut_range_id': cut_range_id,
                'action_type': metadata['action_type'],
                'original_task': metadata['original_task'],
                'new_task': metadata['new_task'],
                'keyframe_index': metadata['keyframe_index'],
                'num_frames': len(frames),
                'frames': frame_files
            }
            
            episodes_info.append(episode_info)
            
            # ä¿å­˜episodeçº§åˆ«çš„å…ƒæ•°æ®
            episode_meta_path = episode_dir / 'metadata.json'
            with open(episode_meta_path, 'w', encoding='utf-8') as f:
                json.dump(episode_info, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ€»ä½“å…ƒæ•°æ®
        summary_path = self.output_dir / 'episodes_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump({
                'total_episodes': len(episodes_info),
                'episodes': episodes_info
            }, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ“ ä¿å­˜äº† {len(episodes_info)} ä¸ªepisodeçš„å›¾ç‰‡")
        print(f"  âœ“ å…ƒæ•°æ®: {summary_path}")
        
        return self.output_dir
    
    @staticmethod
    def _tensor_to_image(tensor_data):
        """å°†Tensorè½¬æ¢ä¸ºPIL Image"""
        if hasattr(tensor_data, 'cpu'):
            tensor_data = tensor_data.cpu()
        if hasattr(tensor_data, 'numpy'):
            tensor_data = tensor_data.numpy()
        
        # CHW -> HWC
        if tensor_data.ndim == 3 and tensor_data.shape[0] == 3:
            tensor_data = tensor_data.transpose(1, 2, 0)
        
        # 0-1 float -> 0-255 uint8
        if tensor_data.dtype != np.uint8:
            if tensor_data.max() <= 1.0:
                tensor_data = (tensor_data * 255).astype(np.uint8)
            else:
                tensor_data = tensor_data.astype(np.uint8)
        
        return Image.fromarray(tensor_data)
    
    def save_as_lerobot_format(self, 
                             episodes_data: Dict[int, Dict],
                             frame_ranges: List[Dict],
                             max_episodes: Optional[int] = None) -> Path:
        """
        å°†æ•°æ®è½¬æ¢ä¸ºLeRobot Parquetæ ¼å¼
        
        Args:
            episodes_data: æŒ‰episodeç»„ç»‡çš„æ•°æ®
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®ä¸ºLeRobot Parquetæ ¼å¼...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        meta_dir = self.output_dir / 'meta' / 'episodes' / 'chunk-000'
        # data_dir = self.output_dir / 'data' / 'chunk-000' # ä¸å†ä½¿ç”¨å•ä¸€çš„chunkç›®å½•
        data_root_dir = self.output_dir / 'data'
        meta_dir.mkdir(parents=True, exist_ok=True)
        data_root_dir.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºepisodeså…ƒæ•°æ®
        episodes_list = []
        global_frame_idx = 0
        
        # ä¿å­˜å¸§æ•°æ®
        print(f"\n  ä¿å­˜å¸§æ•°æ®...")
        file_idx = 0
        
        for cut_range_id, episode_data in sorted(episodes_data.items()):
            if max_episodes and len(episodes_list) >= max_episodes:
                break
            
            frames = episode_data['frames']
            metadata = episode_data['metadata']
            
            num_frames = len(frames)
            
            # å½“å‰æ–°çš„episode index
            new_episode_idx = len(episodes_list)
            
            # ç¡®ä¿æ•´æ•°å€¼ä¸æ˜¯Tensor
            def to_int(val):
                if hasattr(val, 'item'):
                    return int(val.item())
                return int(val)
            
            episode_meta = {
                'episode_index': new_episode_idx,
                'tasks': np.array([metadata['new_task']]),
                'dataset_from_index': global_frame_idx,
                'dataset_to_index': global_frame_idx + num_frames - 1,
                'length': num_frames,
                # ä¿ç•™åŸå§‹ä¿¡æ¯ä½œä¸ºå¤‡æ³¨
                'action_type': metadata['action_type'],
                'original_task': metadata['original_task'],
                'cut_range_id': metadata['cut_range_id'],
                'keyframe_index': to_int(metadata['keyframe_index']),
                'original_episode_index': to_int(metadata['episode_index']),
                'original_task_index': to_int(metadata['task_index'])
            }
            
            episodes_list.append(episode_meta)
            global_frame_idx += num_frames
            
            # å‡†å¤‡å¸§æ•°æ®
            frame_records = []
            for local_idx, frame in enumerate(frames):
                record = {
                    'observation.images.image': frame['observation.images.image'],
                    'observation.images.image2': frame['observation.images.image2'],
                    'observation.state': frame['observation.state'],
                    'action': frame['action'],
                    'timestamp': frame.get('timestamp', torch.tensor(0.0)),
                }
                frame_records.append(record)
            
            # ä¿å­˜ä¸ºparquet
            if frame_records:
                # ä½¿ç”¨åŸå§‹episode indexåˆ›å»ºæ–‡ä»¶å¤¹
                original_ep_idx = to_int(metadata['episode_index'])
                episode_dir = data_root_dir / f'episode_{original_ep_idx}'
                episode_dir.mkdir(parents=True, exist_ok=True)
                
                # æ–‡ä»¶ååŒ…å«æ–°çš„episode indexä»¥åŒºåˆ†åŒä¸€åŸå§‹episodeä¸‹çš„ä¸åŒç‰‡æ®µ
                data_file = episode_dir / f'segment_{new_episode_idx}.parquet'
                
                self._save_frame_batch(frame_records, data_file)
                file_idx += 1
                
                if file_idx % 10 == 0:
                    print(f"    å·²ä¿å­˜ {file_idx} ä¸ªæ•°æ®æ–‡ä»¶")

        # è½¬æ¢ä¸ºDataFrame
        episodes_df = pd.DataFrame(episodes_list)
        
        # ä¿å­˜episodeså…ƒæ•°æ®
        episodes_file = meta_dir / 'file-000.parquet'
        episodes_df.to_parquet(episodes_file, index=False)
        
        print(f"  âœ“ ä¿å­˜episodeså…ƒæ•°æ®: {episodes_file}")
        print(f"    - Episodesæ•°: {len(episodes_df)}")
        print(f"    - æ€»å¸§æ•°: {global_frame_idx}")
        
        # ä¿å­˜tasksåˆ—è¡¨ - æå–å”¯ä¸€çš„ä»»åŠ¡æè¿°
        unique_tasks = set()
        for task_array in episodes_df['tasks']:
            task_str = task_array[0] if isinstance(task_array, np.ndarray) else task_array
            unique_tasks.add(task_str)
        
        tasks_data = []
        for task_idx, task in enumerate(sorted(unique_tasks)):
            tasks_data.append({'task_index': task_idx, 'task': task})
        
        tasks_df = pd.DataFrame(tasks_data)
        tasks_file = self.output_dir / 'meta' / 'tasks.parquet'
        tasks_df.to_parquet(tasks_file, index=False)
        
        print(f"  âœ“ ä¿å­˜tasksåˆ—è¡¨: {tasks_file}")
        print(f"    - Tasksæ•°: {len(tasks_df)}")
        
        print(f"  âœ“ æ€»å…±ä¿å­˜ {file_idx} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # ä¿å­˜å…ƒä¿¡æ¯
        self._save_metadata(meta_dir, episodes_df, tasks_df)
        
        return self.output_dir
    
    def _save_frame_batch(self, frame_records: List[Dict], file_path: Path):
        """
        ä¿å­˜ä¸€æ‰¹å¸§æ•°æ®ä¸ºparquetæ–‡ä»¶ï¼Œä½¿ç”¨LeRobotçš„æ–¹å¼ç¼–ç å›¾åƒ
        """
        from datasets import Dataset, Features, Image as HFImage, Sequence, Value
        
        def to_numpy(val):
            if hasattr(val, 'detach'):
                val = val.detach()
            if hasattr(val, 'cpu'):
                val = val.cpu()
            if hasattr(val, 'numpy'):
                return val.numpy()
            if isinstance(val, list):
                return np.array(val)
            return val
        
        # å°†Tensorå›¾åƒè½¬æ¢ä¸ºPIL Image
        def tensor_to_pil(tensor_data):
            if hasattr(tensor_data, 'cpu'):
                tensor_data = tensor_data.cpu()
            if hasattr(tensor_data, 'numpy'):
                tensor_data = tensor_data.numpy()
            
            # CHW -> HWC
            if tensor_data.ndim == 3 and tensor_data.shape[0] == 3:
                tensor_data = tensor_data.transpose(1, 2, 0)
            
            # 0-1 float -> 0-255 uint8
            if tensor_data.dtype != np.uint8:
                if tensor_data.max() <= 1.0:
                    tensor_data = (tensor_data * 255).astype(np.uint8)
                else:
                    tensor_data = tensor_data.astype(np.uint8)
            
            return Image.fromarray(tensor_data)
        
        # å‡†å¤‡æ•°æ®
        data = {
            'observation.images.image': [tensor_to_pil(f['observation.images.image']) for f in frame_records],
            'observation.images.image2': [tensor_to_pil(f['observation.images.image2']) for f in frame_records],
            'observation.state': [to_numpy(f['observation.state']).tolist() for f in frame_records],
            'action': [to_numpy(f['action']).tolist() for f in frame_records],
            'timestamp': [float(to_numpy(f['timestamp'])) for f in frame_records],
        }
        
        # å®šä¹‰HuggingFace Datasetçš„Features
        features = Features({
            'observation.images.image': HFImage(),
            'observation.images.image2': HFImage(),
            'observation.state': Sequence(Value('float32')),
            'action': Sequence(Value('float32')),
            'timestamp': Value('float32'),
        })
        
        # åˆ›å»ºHuggingFace Dataset
        dataset = Dataset.from_dict(data, features=features)
        
        # å†™å…¥Parquetæ–‡ä»¶
        dataset.to_parquet(file_path)
    
    @staticmethod
    def _save_metadata(meta_dir: Path, episodes_df: pd.DataFrame, tasks_df: pd.DataFrame):
        """
        ä¿å­˜å…ƒä¿¡æ¯æ–‡ä»¶
        """
        # ä¿å­˜info.json
        info = {
            'total_episodes': len(episodes_df),
            'total_frames': episodes_df['length'].sum(),
            'total_tasks': len(tasks_df),
            'created_at': datetime.now().isoformat(),
            'robot_type': 'Panda 7-DOF',
            'observation_keys': ['observation.images.image', 'observation.images.image2', 'observation.state'],
            'action_keys': ['action'],
            'sampling_frequency': 10  # Hz
        }
        
        with open(meta_dir / 'info.json', 'w') as f:
            json.dump(info, f, indent=2, default=str)
        
        # ä¿å­˜stats.json
        stats = {
            'total_episodes': int(len(episodes_df)),
            'total_frames': int(episodes_df['length'].sum()),
            'total_tasks': int(len(tasks_df)),
            'average_frames_per_episode': float(episodes_df['length'].mean()),
            'min_frames_per_episode': int(episodes_df['length'].min()),
            'max_frames_per_episode': int(episodes_df['length'].max()),
        }
        
        with open(meta_dir / 'stats.json', 'w') as f:
            json.dump(stats, f, indent=2, default=str)
        
        print(f"  âœ“ ä¿å­˜å…ƒä¿¡æ¯æ–‡ä»¶")


def cut_and_convert_dataset(dataset,
                           frame_ranges: List[Dict],
                           output_dir: str,
                           save_mode: str = 'lerobot',
                           max_episodes: Optional[int] = None) -> Path:
    """
    å®Œæ•´çš„æ•°æ®é›†è£å‰ªå’Œè½¬æ¢æµç¨‹
    
    Args:
        dataset: åŸå§‹LeRobotæ•°æ®é›†
        frame_ranges: å¸§èŒƒå›´åˆ—è¡¨ï¼ˆåŒ…å«new_taskå­—æ®µï¼‰
        output_dir: è¾“å‡ºç›®å½•
        save_mode: ä¿å­˜æ¨¡å¼ 'image'ï¼ˆå›¾ç‰‡ï¼‰, 'lerobot'ï¼ˆParquetï¼‰, æˆ– 'both'ï¼ˆä¸¤è€…ï¼‰
        max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
        
    Returns:
        è¾“å‡ºç›®å½•è·¯å¾„
    """
    cutter = DatasetCutter(output_dir, save_mode=save_mode)
    
    # æå–å¸§
    extracted_data = cutter.extract_frames(dataset, frame_ranges)
    
    # æŒ‰episodeç»„ç»‡
    episodes_data = cutter.organize_by_episode(extracted_data)
    
    # æ ¹æ®æ¨¡å¼ä¿å­˜
    if save_mode == 'image':
        output_path = cutter.save_as_image_format(episodes_data, frame_ranges, max_episodes)
    elif save_mode == 'lerobot':
        output_path = cutter.save_as_lerobot_format(episodes_data, frame_ranges, max_episodes)
    elif save_mode == 'both':
        print("\nğŸ“¦ ä¿å­˜ä¸¤ç§æ ¼å¼...\n")
        cutter.save_as_image_format(episodes_data, frame_ranges, max_episodes)
        output_path = cutter.save_as_lerobot_format(episodes_data, frame_ranges, max_episodes)
    else:
        raise ValueError(f"Unknown save_mode: {save_mode}. Use 'image', 'lerobot', or 'both'")
    
    return output_path


if __name__ == '__main__':
    print("Dataset Cutter Module")
