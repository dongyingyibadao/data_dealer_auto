"""
æ•°æ®é›†è£å‰ªå’ŒLeRobotæ ¼å¼è½¬æ¢
"""
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
import json
from datetime import datetime
import copy
from PIL import Image
import io
import shutil
import os


class DatasetCutter:
    """
    æ•°æ®é›†è£å‰ªå™¨ - æå–æŒ‡å®šèŒƒå›´çš„å¸§å¹¶æ”¯æŒä¸¤ç§ä¿å­˜æ¨¡å¼ï¼š
    1. å›¾ç‰‡æ¨¡å¼ï¼šä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶ï¼ˆæ–¹ä¾¿æ£€æŸ¥ï¼‰
    2. LeRobotæ¨¡å¼ï¼šä¿å­˜ä¸ºParquetæ ¼å¼ï¼ˆæ–¹ä¾¿è®­ç»ƒï¼‰
    """
    
    def __init__(self, output_dir: Optional[str] = None, save_mode: str = 'lerobot', batch_size: int = 100,
                 insert_placeholders: bool = False, placeholder_action_value: float = -999.0,
                 repo_id: Optional[str] = None, robot_type: str = "panda", fps: float = 10.0,
                 use_official_api: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®é›†è£å‰ªå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            save_mode: ä¿å­˜æ¨¡å¼ 'image' æˆ– 'lerobot' æˆ– 'both'
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯æ¬¡å¤„ç†å¤šå°‘ä¸ªepisodeï¼‰
            insert_placeholders: æ˜¯å¦åœ¨åŒä¸€chunkçš„ä¸åŒsegmentsä¹‹é—´ç‰©ç†æ’å…¥placeholderï¼ˆæ–¹æ¡ˆ3ï¼‰
            placeholder_action_value: placeholderçš„actionå€¼ï¼ˆé»˜è®¤-999.0ï¼‰
            repo_id: HuggingFace repo IDï¼ˆç”¨äºå®˜æ–¹APIï¼‰
            robot_type: æœºå™¨äººç±»å‹ï¼ˆé»˜è®¤"panda"ï¼‰
            fps: é‡‡æ ·é¢‘ç‡ï¼ˆé»˜è®¤10.0ï¼‰
            use_official_api: æ˜¯å¦ä½¿ç”¨LeRobotå®˜æ–¹APIï¼ˆæ¨èï¼‰
        """
        self.output_dir = Path(output_dir) if output_dir else Path('./cut_dataset')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.save_mode = save_mode
        self.batch_size = batch_size
        self.insert_placeholders = insert_placeholders
        self.placeholder_action_value = placeholder_action_value
        self.use_official_api = use_official_api
        self.robot_type = robot_type
        self.fps = fps
        self.episodes_data = []
        self.metadata_buffer = []
        
        # å¦‚æœä½¿ç”¨å®˜æ–¹APIï¼Œåˆå§‹åŒ–LeRobotDataset
        self.lerobot_dataset = None
        if self.use_official_api and save_mode in ['lerobot', 'both']:
            # æ¸…ç†å·²å­˜åœ¨çš„æ•°æ®é›†
            if repo_id is None:
                repo_id = f"custom/{self.output_dir.name}"
            self.repo_id = repo_id
            
            # è‡ªåŠ¨è®¾ç½®HF_LEROBOT_HOMEä¸ºoutput_dir
            lerobot_home = self.output_dir.absolute()
            final_path = lerobot_home / repo_id
            print(f"  ğŸ“ è®¾ç½®æ•°æ®ä¿å­˜è·¯å¾„: {final_path}/")
            
            # ä½¿ç”¨å®˜æ–¹APIåˆ›å»ºæ•°æ®é›†
            try:
                # æ–¹æ¡ˆï¼šå…ˆå¯¼å…¥æ¨¡å—ï¼Œç„¶åä¿®æ”¹å…¶ä¸­çš„HF_LEROBOT_HOMEå˜é‡
                import lerobot.datasets.lerobot_dataset as lrd
                # ä¿®æ”¹æ¨¡å—çº§åˆ«çš„å˜é‡
                lrd.HF_LEROBOT_HOME = lerobot_home
                # ä¿å­˜åˆ°å®ä¾‹å˜é‡
                self._custom_lerobot_home = lerobot_home
                
                from lerobot.datasets.lerobot_dataset import LeRobotDataset
                
                # æ¸…ç†å·²æœ‰æ•°æ®é›†
                dataset_path = lerobot_home / repo_id
                if dataset_path.exists():
                    print(f"  âš ï¸  æ¸…ç†å·²å­˜åœ¨çš„æ•°æ®é›†: {dataset_path}")
                    shutil.rmtree(dataset_path)
                
                print(f"  ğŸ”§ ä½¿ç”¨LeRobotå®˜æ–¹APIåˆ›å»ºæ•°æ®é›†: {repo_id}")
                self.lerobot_dataset = LeRobotDataset.create(
                    repo_id=repo_id,
                    robot_type=robot_type,
                    fps=int(fps),
                    features={
                        "observation.images.image": {
                            "dtype": "image",
                            "shape": (256, 256, 3),
                            "names": ["height", "width", "channel"],
                        },
                        "observation.images.image2": {
                            "dtype": "image",
                            "shape": (256, 256, 3),
                            "names": ["height", "width", "channel"],
                        },
                        "observation.state": {
                            "dtype": "float32",
                            "shape": (8,),
                            "names": ["state"],
                        },
                        "action": {
                            "dtype": "float32",
                            "shape": (7,),
                            "names": ["actions"],
                        },
                        "timestamp": {
                            "dtype": "float32",
                            "shape": (1,),
                            "names": None,
                        },
                        "frame_index": {
                            "dtype": "int64",
                            "shape": (1,),
                            "names": None,
                        },
                        "episode_index": {
                            "dtype": "int64",
                            "shape": (1,),
                            "names": None,
                        },
                        "index": {
                            "dtype": "int64",
                            "shape": (1,),
                            "names": None,
                        },
                        "task_index": {
                            "dtype": "int64",
                            "shape": (1,),
                            "names": None,
                        },
                        "is_last_segment":{
                            "dtype": "bool",
                            "shape": (1,),
                            "names": None,
                        }
                        
                    },
                    image_writer_threads=10,  # å¹¶è¡Œä¼˜åŒ–
                    image_writer_processes=5,
                )
                print(f"  âœ… LeRobotæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                print(f"  âš ï¸  LeRobotå®˜æ–¹APIåˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"  â„¹ï¸  å°†ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ä¿å­˜æ•°æ®")
                self.use_official_api = False
                self.lerobot_dataset = None
    
    def extract_frames_batch(self, 
                            dataset,
                            frame_ranges: List[Dict],
                            batch_start: int = 0,
                            batch_end: Optional[int] = None,
                            verbose: bool = True) -> List[Dict]:
        """
        ä»æ•°æ®é›†ä¸­æ‰¹é‡æå–æŒ‡å®šèŒƒå›´çš„å¸§ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ï¼‰
        
        Args:
            dataset: LeRobotæ•°æ®é›†
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            batch_start: æ‰¹æ¬¡èµ·å§‹ç´¢å¼•
            batch_end: æ‰¹æ¬¡ç»“æŸç´¢å¼•ï¼ˆNoneè¡¨ç¤ºåˆ°æœ«å°¾ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        Returns:
            æå–çš„æ•°æ®åˆ—è¡¨
        """
        extracted_data = []
        batch_end = batch_end or len(frame_ranges)
        
        if verbose:
            print(f"ğŸ“¥ æå–å¸§æ•°æ®æ‰¹æ¬¡ [{batch_start}:{batch_end}]...")
        
        for range_idx in range(batch_start, batch_end):
            if verbose and (range_idx - batch_start) % 10 == 0:
                print(f"  å¤„ç†èŒƒå›´ {range_idx}/{batch_end}")
            
            frame_range = frame_ranges[range_idx]
            start_idx = frame_range['frame_start']
            end_idx = frame_range['frame_end']
            
            for frame_idx in range(start_idx, end_idx):
                try:
                    item = dataset[frame_idx]
                    
                    # åªæå–éœ€è¦çš„å­—æ®µï¼Œä¸ä½¿ç”¨ deepcopyï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
                    new_item = {
                        'observation.images.image': item['observation.images.image'].clone().detach() if hasattr(item['observation.images.image'], 'clone') else item['observation.images.image'],
                        'observation.images.image2': item['observation.images.image2'].clone().detach() if hasattr(item['observation.images.image2'], 'clone') else item['observation.images.image2'],
                        'observation.state': item['observation.state'].clone().detach() if hasattr(item['observation.state'], 'clone') else item['observation.state'],
                        'action': item['action'].clone().detach() if hasattr(item['action'], 'clone') else item['action'],
                        'timestamp': item.get('timestamp', torch.tensor(0.0)),
                        'frame_index': item.get('frame_index', torch.tensor(0)),
                        'episode_index': item.get('episode_index', torch.tensor(0)),
                        'task_index': item.get('task_index', torch.tensor(0)),
                    }
                    
                    # æ·»åŠ å…ƒæ•°æ®
                    new_item['original_index'] = frame_idx
                    new_item['cut_range_id'] = range_idx
                    new_item['original_task'] = frame_range.get('original_task', frame_range.get('task', ''))
                    new_item['new_task'] = frame_range.get('new_task', frame_range.get('original_task', frame_range.get('task', '')))
                    new_item['action_type'] = frame_range['action_type']
                    new_item['keyframe_index'] = frame_range['keyframe_index']
                    
                    extracted_data.append(new_item)
                
                except Exception as e:
                    if verbose:
                        print(f"âš ï¸  æå–ç´¢å¼• {frame_idx} æ—¶å‡ºé”™: {e}")
                    continue
        
        if verbose:
            print(f"âœ“ æ‰¹æ¬¡æå–å®Œæˆï¼Œå…± {len(extracted_data)} å¸§")
        
        return extracted_data
    
    def organize_by_episode(self, 
                           extracted_data: List[Dict]) -> Dict[int, Dict]:
        """
        æŒ‰episodeç»„ç»‡æå–çš„æ•°æ®
        
        Args:
            extracted_data: æå–çš„æ•°æ®åˆ—è¡¨
            
        Returns:
            æŒ‰episode_indexç»„ç»‡çš„æ•°æ®å­—å…¸
        """
        episodes = {}
        
        for item in extracted_data:
            cut_range_id = item['cut_range_id']
            if cut_range_id not in episodes:
                episodes[cut_range_id] = {
                    'frames': [],
                    'metadata': {
                        'cut_range_id': cut_range_id,
                        'action_type': item['action_type'],
                        'original_task': item['original_task'],
                        'new_task': item['new_task'],
                        'episode_index': item.get('episode_index', -1),
                        'task_index': item.get('task_index', -1),
                        'keyframe_index': item['keyframe_index']
                    }
                }
            
            episodes[cut_range_id]['frames'].append(item)
        
        return episodes
    
    def save_as_image_format(self,
                           episodes_data: Dict[int, Dict],
                           frame_ranges: List[Dict],
                           max_episodes: Optional[int] = None) -> Path:
        """
        å°†æ•°æ®ä¿å­˜ä¸ºå›¾ç‰‡æ ¼å¼ï¼ˆç±»ä¼¼data_dealerï¼‰
        
        Args:
            episodes_data: æŒ‰episodeç»„ç»‡çš„æ•°æ®
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®ä¸ºå›¾ç‰‡æ ¼å¼...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        images_dir = self.output_dir / 'images'
        images_dir.mkdir(parents=True, exist_ok=True)
        
        episodes_info = []
        
        for cut_range_id, episode_data in sorted(episodes_data.items()):
            if max_episodes and len(episodes_info) >= max_episodes:
                break
            
            frames = episode_data['frames']
            metadata = episode_data['metadata']
            
            episode_idx = len(episodes_info)
            episode_dir = images_dir / f"episode_{episode_idx:04d}"
            episode_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜æ¯ä¸€å¸§çš„å›¾åƒ
            frame_files = []
            for frame_idx, frame_data in enumerate(frames):
                # ä¿å­˜ä¸»æ‘„åƒå¤´å›¾åƒ
                img1 = self._tensor_to_image(frame_data['observation.images.image'])
                img1_path = episode_dir / f"frame_cam1_{frame_idx:04d}.jpg"
                img1.save(img1_path, quality=95)
                
                # ä¿å­˜ç¬¬äºŒæ‘„åƒå¤´å›¾åƒ
                img2 = self._tensor_to_image(frame_data['observation.images.image2'])
                img2_path = episode_dir / f"frame_cam2_{frame_idx:04d}.jpg"
                img2.save(img2_path, quality=95)
                
                frame_files.append({
                    'frame_idx': frame_idx,
                    'cam1': str(img1_path.relative_to(self.output_dir)),
                    'cam2': str(img2_path.relative_to(self.output_dir)),
                    'action': frame_data['action'].cpu().numpy().tolist() if hasattr(frame_data['action'], 'cpu') else frame_data['action'].tolist(),
                    'state': frame_data['observation.state'].cpu().numpy().tolist() if hasattr(frame_data['observation.state'], 'cpu') else frame_data['observation.state'].tolist(),
                })
            
            episode_info = {
                'episode_idx': episode_idx,
                'cut_range_id': cut_range_id,
                'action_type': metadata['action_type'],
                'original_task': metadata['original_task'],
                'new_task': metadata['new_task'],
                'keyframe_index': metadata['keyframe_index'],
                'num_frames': len(frames),
                'frames': frame_files
            }
            
            episodes_info.append(episode_info)
            
            # ä¿å­˜episodeçº§åˆ«çš„å…ƒæ•°æ®
            episode_meta_path = episode_dir / 'metadata.json'
            with open(episode_meta_path, 'w', encoding='utf-8') as f:
                json.dump(episode_info, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ€»ä½“å…ƒæ•°æ®
        summary_path = self.output_dir / 'episodes_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump({
                'total_episodes': len(episodes_info),
                'episodes': episodes_info
            }, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ“ ä¿å­˜äº† {len(episodes_info)} ä¸ªepisodeçš„å›¾ç‰‡")
        print(f"  âœ“ å…ƒæ•°æ®: {summary_path}")
        
        return self.output_dir
    
    def _create_placeholder_frame(self, previous_frame: Dict, episode_index: int, 
                                  global_frame_idx: int, task_index: int) -> Dict:
        """
        åˆ›å»ºä¸€ä¸ªplaceholderå¸§ï¼ˆæ–¹æ¡ˆ3ï¼šç‰©ç†å†™å…¥ï¼‰
        
        Args:
            previous_frame: å‰ä¸€å¸§çš„æ•°æ®ï¼ˆç”¨äºå¤åˆ¶observationï¼‰
            episode_index: å½“å‰episodeç´¢å¼•
            global_frame_idx: å…¨å±€å¸§ç´¢å¼•
            task_index: ä»»åŠ¡ç´¢å¼•
            
        Returns:
            placeholderå¸§æ•°æ®
        """
        # å¤åˆ¶observationï¼ˆå›¾åƒå’ŒçŠ¶æ€ï¼‰
        placeholder = {
            'observation.images.image': previous_frame['observation.images.image'].clone(),
            'observation.images.image2': previous_frame['observation.images.image2'].clone(),
            'observation.state': previous_frame['observation.state'].clone(),
        }
        
        # è®¾ç½®ç‰¹æ®Šçš„actionå€¼ï¼ˆå…¨ä¸ºplaceholder_action_valueï¼‰
        action_shape = previous_frame['action'].shape
        placeholder['action'] = torch.full(action_shape, self.placeholder_action_value, 
                                          dtype=previous_frame['action'].dtype)
        
        # è®¾ç½®å…ƒæ•°æ®
        placeholder['timestamp'] = previous_frame.get('timestamp', torch.tensor(0.0))
        placeholder['episode_index'] = torch.tensor(episode_index)
        placeholder['frame_index'] = torch.tensor(-1)  # ç‰¹æ®Šæ ‡è®°
        placeholder['index'] = torch.tensor(global_frame_idx)
        placeholder['task_index'] = torch.tensor(task_index)
        
        return placeholder
    
    @staticmethod
    def _tensor_to_image(tensor_data):
        """å°†Tensorè½¬æ¢ä¸ºPIL Image"""
        if hasattr(tensor_data, 'cpu'):
            tensor_data = tensor_data.cpu()
        if hasattr(tensor_data, 'numpy'):
            tensor_data = tensor_data.numpy()
        
        # CHW -> HWC
        if tensor_data.ndim == 3 and tensor_data.shape[0] == 3:
            tensor_data = tensor_data.transpose(1, 2, 0)
        
        # 0-1 float -> 0-255 uint8
        if tensor_data.dtype != np.uint8:
            if tensor_data.max() <= 1.0:
                tensor_data = (tensor_data * 255).astype(np.uint8)
            else:
                tensor_data = tensor_data.astype(np.uint8)
        
        return Image.fromarray(tensor_data)
    
    @staticmethod
    def _tensor_to_numpy_image(tensor_data):
        """å°†Tensorè½¬æ¢ä¸ºnumpyå›¾åƒï¼ˆç”¨äºLeRobot APIï¼‰"""
        if hasattr(tensor_data, 'cpu'):
            tensor_data = tensor_data.cpu()
        if hasattr(tensor_data, 'numpy'):
            tensor_data = tensor_data.numpy()
        
        # CHW -> HWC
        if tensor_data.ndim == 3 and tensor_data.shape[0] == 3:
            tensor_data = tensor_data.transpose(1, 2, 0)
        
        # 0-1 float -> 0-255 uint8
        if tensor_data.dtype != np.uint8:
            if tensor_data.max() <= 1.0:
                tensor_data = (tensor_data * 255).astype(np.uint8)
            else:
                tensor_data = tensor_data.astype(np.uint8)
        
        return tensor_data
    
    @staticmethod
    def _tensor_to_numpy(tensor_data):
        """å°†Tensorè½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if hasattr(tensor_data, 'cpu'):
            tensor_data = tensor_data.cpu()
        if hasattr(tensor_data, 'numpy'):
            return tensor_data.numpy()
        return np.array(tensor_data)
    
    def save_as_lerobot_format_streaming(self,
                                        dataset,
                                        frame_ranges: List[Dict],
                                        max_episodes: Optional[int] = None) -> Path:
        """
        æµå¼ä¿å­˜æ•°æ®ä¸ºLeRobotæ ¼å¼ï¼ˆæ‰¹å¤„ç†ï¼ŒèŠ‚çœå†…å­˜ï¼‰
        æ”¯æŒä½¿ç”¨å®˜æ–¹APIæˆ–ä¼ ç»Ÿæ–¹æ³•
        
        Args:
            dataset: åŸå§‹LeRobotæ•°æ®é›†
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        # å¦‚æœä½¿ç”¨å®˜æ–¹API
        if self.use_official_api and self.lerobot_dataset is not None:
            return self._save_with_official_api(dataset, frame_ranges, max_episodes)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
            return self._save_with_traditional_method(dataset, frame_ranges, max_episodes)
    
    def _save_with_official_api(self,
                                dataset,
                                frame_ranges: List[Dict],
                                max_episodes: Optional[int] = None) -> Path:
        """
        ä½¿ç”¨LeRobotå®˜æ–¹APIä¿å­˜æ•°æ®
        
        Args:
            dataset: åŸå§‹LeRobotæ•°æ®é›†
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ’¾ ä½¿ç”¨LeRobotå®˜æ–¹APIä¿å­˜æ•°æ®...")
        print(f"  æ‰¹å¤„ç†å¤§å°: {self.batch_size} episodes/æ‰¹")

        if self.lerobot_dataset is None:
            raise RuntimeError("LeRobot dataset æœªåˆå§‹åŒ–")
        lrd = self.lerobot_dataset
        
        # é™åˆ¶episodeæ•°é‡
        total_ranges = min(len(frame_ranges), max_episodes) if max_episodes else len(frame_ranges)
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, total_ranges, self.batch_size):
            batch_end = min(batch_start + self.batch_size, total_ranges)
            
            print(f"\n  å¤„ç†æ‰¹æ¬¡ [{batch_start}:{batch_end}]/{total_ranges}")
            
            # æå–å½“å‰æ‰¹æ¬¡çš„å¸§æ•°æ®
            extracted_data = self.extract_frames_batch(
                dataset, frame_ranges, batch_start, batch_end, verbose=False
            )
            
            # æŒ‰episodeç»„ç»‡
            episodes_data = self.organize_by_episode(extracted_data)
            
            # å¤„ç†æ¯ä¸ªepisode
            # ç”¨äºç¼“å­˜ä¸‹ä¸€ä¸ªepisodeéœ€è¦çš„placeholder
            # pending_placeholder = None
            
            for cut_range_id, episode_data in sorted(episodes_data.items()):
                frames = episode_data['frames']
                metadata = episode_data['metadata']
                task_name = metadata['new_task']
                
                
                # åˆ¤æ–­è¯¥segmentæ˜¯å¦ä¸ºåŸå§‹episodeçš„æœ€åä¸€ä¸ªç‰‡æ®µ
                is_last_segment = False
                next_idx = cut_range_id + 1
                if next_idx < len(frame_ranges):
                    next_metadata = frame_ranges[next_idx]
                    if next_metadata.get('episode_index', -1) != metadata['episode_index']:
                        is_last_segment = True
                else:
                    is_last_segment= True
                
                is_last_segment = np.array([is_last_segment])
                # ä½¿ç”¨å®˜æ–¹APIé€å¸§æ·»åŠ 
                for frame_idx, frame in enumerate(frames):
                    # è½¬æ¢å›¾åƒæ ¼å¼ï¼ˆLeRobot APIéœ€è¦numpyæ ¼å¼ï¼‰
                    image1 = self._tensor_to_numpy_image(frame['observation.images.image'])
                    image2 = self._tensor_to_numpy_image(frame['observation.images.image2'])
                    state = self._tensor_to_numpy(frame['observation.state'])
                    action = self._tensor_to_numpy(frame['action'])
                    
                    # æ³¨æ„ï¼štimestamp, frame_index, episode_index, index, task_index
                    # è¿™äº›å­—æ®µç”±å®˜æ–¹APIè‡ªåŠ¨ç”Ÿæˆï¼Œä¸éœ€è¦æ‰‹åŠ¨ä¼ å…¥
                    lrd.add_frame({
                        "observation.images.image": image1,
                        "observation.images.image2": image2,
                        "observation.state": state,
                        "action": action,
                        "task": task_name,
                        "is_last_segment": is_last_segment,
                    })
                
                if self.insert_placeholders:
                    placeholder_action = np.full((7,), self.placeholder_action_value, dtype=np.float32)
                    last_frame = frames[-1]
                    image1 = self._tensor_to_numpy_image(last_frame['observation.images.image'])
                    image2 = self._tensor_to_numpy_image(last_frame['observation.images.image2'])
                    state = self._tensor_to_numpy(last_frame['observation.state'])
                    

                    lrd.add_frame({
                        "observation.images.image": image1,
                        "observation.images.image2": image2,
                        "observation.state": state,
                        "action": placeholder_action,
                        "task": task_name,
                        "is_last_segment": is_last_segment,
                    })
                
                
                # # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸ºå½“å‰episodeæœ«å°¾å‡†å¤‡placeholder
                # if self.insert_placeholders:
                #     next_idx = cut_range_id + 1
                #     if next_idx < len(frame_ranges):
                #         next_metadata = frame_ranges[next_idx]
                #         if next_metadata.get('episode_index', -1) == metadata['episode_index']:
                #             # åŒä¸€ä¸ªchunkï¼Œå‡†å¤‡placeholderï¼ˆå°†åœ¨å½“å‰episodeæœ«å°¾æ’å…¥ï¼‰
                #             last_frame = frames[-1]
                #             image1 = self._tensor_to_numpy_image(last_frame['observation.images.image'])
                #             image2 = self._tensor_to_numpy_image(last_frame['observation.images.image2'])
                #             state = self._tensor_to_numpy(last_frame['observation.state'])
                            
                #             # Placeholder actionå…¨ä¸ºç‰¹æ®Šå€¼
                #             placeholder_action = np.full((7,), self.placeholder_action_value, dtype=np.float32)
                            
                #             # å‡†å¤‡placeholderæ•°æ®
                #             pending_placeholder = {
                #                 "observation.images.image": image1,
                #                 "observation.images.image2": image2,
                #                 "observation.state": state,
                #                 "action": placeholder_action,
                #                 # "task": f"[PLACEHOLDER] {task_name}â†’{next_metadata.get('new_task', '')}",
                #                 "task": task_name,
                #             }
                
                # ä¿å­˜episodeï¼ˆä¸åŒ…å«placeholderï¼‰
                lrd.save_episode()
            
            print(f"  âœ“ æ‰¹æ¬¡å®Œæˆï¼Œå·²ä¿å­˜ {len(episodes_data)} episodes")
            
            # æ¸…ç†å†…å­˜
            del extracted_data
            del episodes_data
            import gc
            gc.collect()
        
        print(f"\nâœ… ä½¿ç”¨å®˜æ–¹APIä¿å­˜å®Œæˆ!")
        print(f"  æ€»episodes: {total_ranges}")
        
        # è¿”å›æ•°æ®é›†è·¯å¾„ï¼ˆä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰çš„è·¯å¾„ï¼‰
        return self._custom_lerobot_home / self.repo_id
    
    def _save_with_traditional_method(self,
                                     dataset,
                                     frame_ranges: List[Dict],
                                     max_episodes: Optional[int] = None) -> Path:
        """
        ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ä¿å­˜æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
        
        Args:
            dataset: åŸå§‹LeRobotæ•°æ®é›†
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ’¾ ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ä¿å­˜æ•°æ®...")
        print(f"  æ‰¹å¤„ç†å¤§å°: {self.batch_size} episodes/æ‰¹")
        
        # é¦–å…ˆæ„å»ºä»»åŠ¡æ˜ å°„è¡¨
        task_to_index = {}
        for frame_range in frame_ranges:
            task_desc = frame_range.get('new_task', frame_range.get('task', ''))
            if task_desc not in task_to_index:
                task_to_index[task_desc] = len(task_to_index)
        
        print(f"\n  ä»»åŠ¡æ˜ å°„è¡¨:")
        for task, idx in sorted(task_to_index.items(), key=lambda x: x[1]):
            print(f"    {idx}: {task}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        meta_dir = self.output_dir / 'meta' / 'episodes' / 'chunk-000'
        data_root_dir = self.output_dir / 'data'
        meta_dir.mkdir(parents=True, exist_ok=True)
        data_root_dir.mkdir(parents=True, exist_ok=True)
        
        # æµå¼å¤„ç†
        episodes_list = []
        global_frame_idx = 0
        file_idx = 0
        
        # é™åˆ¶episodeæ•°é‡
        total_ranges = min(len(frame_ranges), max_episodes) if max_episodes else len(frame_ranges)
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, total_ranges, self.batch_size):
            batch_end = min(batch_start + self.batch_size, total_ranges)
            
            print(f"\n  å¤„ç†æ‰¹æ¬¡ [{batch_start}:{batch_end}]/{total_ranges}")
            
            # æå–å½“å‰æ‰¹æ¬¡çš„å¸§æ•°æ®
            extracted_data = self.extract_frames_batch(
                dataset, frame_ranges, batch_start, batch_end, verbose=False
            )
            
            # æŒ‰episodeç»„ç»‡
            episodes_data = self.organize_by_episode(extracted_data)
            
            # ä¿å­˜å½“å‰æ‰¹æ¬¡
            for cut_range_id, episode_data in sorted(episodes_data.items()):
                frames = episode_data['frames']
                metadata = episode_data['metadata']
                
                num_frames = len(frames)
                new_episode_idx = len(episodes_list)
                
                # ç¡®ä¿æ•´æ•°å€¼ä¸æ˜¯Tensor
                def to_int(val):
                    if hasattr(val, 'item'):
                        return int(val.item())
                    return int(val)
                
                episode_meta = {
                    'episode_index': new_episode_idx,
                    'tasks': np.array([metadata['new_task']]),
                    'data/chunk_index': to_int(metadata['episode_index']),
                    'data/file_index': new_episode_idx,
                    'dataset_from_index': global_frame_idx,
                    'dataset_to_index': global_frame_idx + num_frames - 1,
                    'length': num_frames,
                    'action_type': metadata['action_type'],
                    'original_task': metadata['original_task'],
                    'cut_range_id': metadata['cut_range_id'],
                    'keyframe_index': to_int(metadata['keyframe_index']),
                    'original_episode_index': to_int(metadata['episode_index']),
                    'original_task_index': to_int(metadata['task_index'])
                }
                
                episodes_list.append(episode_meta)
                global_frame_idx += num_frames
                
                # è·å–å½“å‰episodeçš„task_index
                current_task = metadata['new_task']
                current_task_index = task_to_index[current_task]
                
                # å‡†å¤‡å¸§æ•°æ®
                frame_records = []
                for local_idx, frame in enumerate(frames):
                    record = {
                        'observation.images.image': frame['observation.images.image'],
                        'observation.images.image2': frame['observation.images.image2'],
                        'observation.state': frame['observation.state'],
                        'action': frame['action'],
                        'timestamp': frame.get('timestamp', torch.tensor(0.0)),
                        'episode_index': torch.tensor(new_episode_idx),
                        'frame_index': torch.tensor(local_idx),
                        'index': torch.tensor(global_frame_idx - num_frames + local_idx),
                        'task_index': torch.tensor(current_task_index),
                    }
                    frame_records.append(record)
                
                # æ’å…¥placeholderï¼ˆå¦‚æœå¯ç”¨ä¸”ä¸æ˜¯æœ€åä¸€ä¸ªepisodeï¼‰
                placeholder_added = False
                if self.insert_placeholders and new_episode_idx < total_ranges - 1:
                    # æ£€æŸ¥ä¸‹ä¸€ä¸ªepisodeæ˜¯å¦å±äºåŒä¸€ä¸ªchunk
                    next_idx = cut_range_id + 1
                    if next_idx < len(frame_ranges):
                        next_metadata = frame_ranges[next_idx]
                        if next_metadata.get('episode_index', -1) == metadata['episode_index']:
                            # åŒä¸€ä¸ªchunkï¼Œå°†placeholderè¿½åŠ åˆ°å½“å‰segment
                            placeholder_frame_dict = self._create_placeholder_frame(
                                frames[-1],  # ä½¿ç”¨å½“å‰segmentçš„æœ€åä¸€å¸§
                                new_episode_idx,
                                global_frame_idx,  # placeholderä½¿ç”¨ä¸‹ä¸€ä¸ªframeçš„index
                                current_task_index
                            )
                            
                            # å°†placeholderä½œä¸ºé¢å¤–å¸§è¿½åŠ åˆ°frame_records
                            frame_records.append(placeholder_frame_dict)
                            global_frame_idx += 1  # placeholderå ç”¨ä¸€ä¸ªframe
                            placeholder_added = True
                            
                            if new_episode_idx < 3:  # åªæ‰“å°å‰å‡ ä¸ª
                                print(f"  âš¡ æ’å…¥placeholder @ ç´¢å¼• {global_frame_idx-1} (è¿½åŠ åˆ° segment {new_episode_idx})")
                
                # ä¿å­˜ä¸ºparquetï¼ˆåŒ…å«å¯èƒ½çš„placeholderå¸§ï¼‰
                if frame_records:
                    original_ep_idx = to_int(metadata['episode_index'])
                    episode_dir = data_root_dir / f'episode_{original_ep_idx}'
                    episode_dir.mkdir(parents=True, exist_ok=True)
                    
                    data_file = episode_dir / f'segment_{new_episode_idx}.parquet'
                    self._save_frame_batch(frame_records, data_file)
                    file_idx += 1
                
                # è°ƒæ•´episode metadataä»¥åŒ…å«placeholder
                if placeholder_added:
                    episode_meta['length'] += 1  # å¢åŠ 1å¸§ï¼ˆplaceholderï¼‰
                    episode_meta['dataset_to_index'] += 1  # ç»“æŸç´¢å¼•åç§»
            
            # æ¸…ç†å†…å­˜
            del extracted_data
            del episodes_data
            import gc
            gc.collect()
            
            print(f"  âœ“ æ‰¹æ¬¡å®Œæˆï¼Œå·²å¤„ç† {len(episodes_list)} episodes, {file_idx} æ–‡ä»¶")
        
        # ä¿å­˜å…ƒæ•°æ®
        episodes_df = pd.DataFrame(episodes_list)
        episodes_file = meta_dir / 'file-000.parquet'
        episodes_df.to_parquet(episodes_file, index=False)
        
        print(f"\n  âœ“ ä¿å­˜episodeså…ƒæ•°æ®: {episodes_file}")
        print(f"    - Episodesæ•°: {len(episodes_df)}")
        print(f"    - æ€»å¸§æ•°: {global_frame_idx}")
        
        # ä¿å­˜tasksåˆ—è¡¨
        tasks_data = []
        for task, task_idx in sorted(task_to_index.items(), key=lambda x: x[1]):
            tasks_data.append({'task': task, 'task_index': task_idx})
        
        tasks_df = pd.DataFrame(tasks_data)
        tasks_df = tasks_df.set_index('task')
        tasks_file = self.output_dir / 'meta' / 'tasks.parquet'
        tasks_df.to_parquet(tasks_file, index=True)
        
        print(f"  âœ“ ä¿å­˜tasksåˆ—è¡¨: {tasks_file}")
        print(f"    - Tasksæ•°: {len(tasks_df)}")
        print(f"  âœ“ æ€»å…±ä¿å­˜ {file_idx} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # ä¿å­˜å…ƒä¿¡æ¯
        root_meta_dir = self.output_dir / 'meta'
        self._save_metadata(root_meta_dir, episodes_df, tasks_df)
        
        return self.output_dir
    
    def save_as_lerobot_format(self, 
                             episodes_data: Dict[int, Dict],
                             frame_ranges: List[Dict],
                             max_episodes: Optional[int] = None) -> Path:
        """
        å°†æ•°æ®è½¬æ¢ä¸ºLeRobot Parquetæ ¼å¼ï¼ˆæ—§ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
        
        Args:
            episodes_data: æŒ‰episodeç»„ç»‡çš„æ•°æ®
            frame_ranges: å¸§èŒƒå›´åˆ—è¡¨
            max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®ä¸ºLeRobot Parquetæ ¼å¼...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        meta_dir = self.output_dir / 'meta' / 'episodes' / 'chunk-000'
        # data_dir = self.output_dir / 'data' / 'chunk-000' # ä¸å†ä½¿ç”¨å•ä¸€çš„chunkç›®å½•
        data_root_dir = self.output_dir / 'data'
        meta_dir.mkdir(parents=True, exist_ok=True)
        data_root_dir.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºepisodeså…ƒæ•°æ®
        episodes_list = []
        global_frame_idx = 0
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ä»»åŠ¡æè¿°ï¼Œæ„å»ºä»»åŠ¡ç´¢å¼•æ˜ å°„
        task_to_index = {}
        for cut_range_id, episode_data in sorted(episodes_data.items()):
            task_desc = episode_data['metadata']['new_task']
            if task_desc not in task_to_index:
                task_to_index[task_desc] = len(task_to_index)
        
        print(f"\n  ä»»åŠ¡æ˜ å°„è¡¨:")
        for task, idx in sorted(task_to_index.items(), key=lambda x: x[1]):
            print(f"    {idx}: {task}")
        
        # ä¿å­˜å¸§æ•°æ®
        print(f"\n  ä¿å­˜å¸§æ•°æ®...")
        file_idx = 0
        
        for cut_range_id, episode_data in sorted(episodes_data.items()):
            if max_episodes and len(episodes_list) >= max_episodes:
                break
            
            frames = episode_data['frames']
            metadata = episode_data['metadata']
            
            num_frames = len(frames)
            
            # å½“å‰æ–°çš„episode index
            new_episode_idx = len(episodes_list)
            
            # ç¡®ä¿æ•´æ•°å€¼ä¸æ˜¯Tensor
            def to_int(val):
                if hasattr(val, 'item'):
                    return int(val.item())
                return int(val)
            
            episode_meta = {
                'episode_index': new_episode_idx,
                'tasks': np.array([metadata['new_task']]),
                # LeRobot required: data file location
                'data/chunk_index': to_int(metadata['episode_index']),  # ä½¿ç”¨åŸå§‹episodeä½œä¸ºchunk
                'data/file_index': new_episode_idx,  # ä½¿ç”¨æ–°episode indexä½œä¸ºfile index
                'dataset_from_index': global_frame_idx,
                'dataset_to_index': global_frame_idx + num_frames - 1,
                'length': num_frames,
                # ä¿ç•™åŸå§‹ä¿¡æ¯ä½œä¸ºå¤‡æ³¨
                'action_type': metadata['action_type'],
                'original_task': metadata['original_task'],
                'cut_range_id': metadata['cut_range_id'],
                'keyframe_index': to_int(metadata['keyframe_index']),
                'original_episode_index': to_int(metadata['episode_index']),
                'original_task_index': to_int(metadata['task_index'])
            }
            
            episodes_list.append(episode_meta)
            global_frame_idx += num_frames
            
            # è·å–å½“å‰episodeçš„task_index
            current_task = metadata['new_task']
            current_task_index = task_to_index[current_task]
            
            # å‡†å¤‡å¸§æ•°æ®
            frame_records = []
            for local_idx, frame in enumerate(frames):
                record = {
                    'observation.images.image': frame['observation.images.image'],
                    'observation.images.image2': frame['observation.images.image2'],
                    'observation.state': frame['observation.state'],
                    'action': frame['action'],
                    'timestamp': frame.get('timestamp', torch.tensor(0.0)),
                    # æ·»åŠ å¿…éœ€çš„å…ƒæ•°æ®å­—æ®µ - å¼ºåˆ¶ä½¿ç”¨æ–°çš„ç´¢å¼•å€¼
                    'episode_index': torch.tensor(new_episode_idx),  # ä½¿ç”¨æ–°episodeç´¢å¼•
                    'frame_index': torch.tensor(local_idx),  # ä½¿ç”¨å±€éƒ¨å¸§ç´¢å¼•
                    'index': torch.tensor(global_frame_idx - num_frames + local_idx),  # å…¨å±€ç´¢å¼•
                    'task_index': torch.tensor(current_task_index),  # ä½¿ç”¨æ­£ç¡®çš„ä»»åŠ¡ç´¢å¼•
                }
                frame_records.append(record)
            
            # ä¿å­˜ä¸ºparquet
            if frame_records:
                # ä½¿ç”¨åŸå§‹episode indexåˆ›å»ºæ–‡ä»¶å¤¹
                original_ep_idx = to_int(metadata['episode_index'])
                episode_dir = data_root_dir / f'episode_{original_ep_idx}'
                episode_dir.mkdir(parents=True, exist_ok=True)
                
                # æ–‡ä»¶ååŒ…å«æ–°çš„episode indexä»¥åŒºåˆ†åŒä¸€åŸå§‹episodeä¸‹çš„ä¸åŒç‰‡æ®µ
                data_file = episode_dir / f'segment_{new_episode_idx}.parquet'
                
                self._save_frame_batch(frame_records, data_file)
                file_idx += 1
                
                if file_idx % 10 == 0:
                    print(f"    å·²ä¿å­˜ {file_idx} ä¸ªæ•°æ®æ–‡ä»¶")

        # è½¬æ¢ä¸ºDataFrame
        episodes_df = pd.DataFrame(episodes_list)
        
        # ä¿å­˜episodeså…ƒæ•°æ®
        episodes_file = meta_dir / 'file-000.parquet'
        episodes_df.to_parquet(episodes_file, index=False)
        
        print(f"  âœ“ ä¿å­˜episodeså…ƒæ•°æ®: {episodes_file}")
        print(f"    - Episodesæ•°: {len(episodes_df)}")
        print(f"    - æ€»å¸§æ•°: {global_frame_idx}")
        
        # ä¿å­˜tasksåˆ—è¡¨ - ä½¿ç”¨é¢„å…ˆæ„å»ºçš„ä»»åŠ¡æ˜ å°„
        # æ³¨æ„ï¼šä»»åŠ¡æè¿°åº”è¯¥ä½œä¸ºDataFrameçš„indexï¼ˆè¡Œåï¼‰ï¼Œtask_indexä½œä¸ºåˆ—
        tasks_data = []
        for task, task_idx in sorted(task_to_index.items(), key=lambda x: x[1]):
            tasks_data.append({'task': task, 'task_index': task_idx})
        
        tasks_df = pd.DataFrame(tasks_data)
        # å°†ä»»åŠ¡æè¿°è®¾ä¸ºindexï¼ˆè¿™æ˜¯LeRobotæœŸæœ›çš„æ ¼å¼ï¼‰
        tasks_df = tasks_df.set_index('task')
        tasks_file = self.output_dir / 'meta' / 'tasks.parquet'
        tasks_df.to_parquet(tasks_file, index=True)  # ç¡®ä¿ä¿å­˜index
        
        print(f"  âœ“ ä¿å­˜tasksåˆ—è¡¨: {tasks_file}")
        print(f"    - Tasksæ•°: {len(tasks_df)}")
        
        print(f"  âœ“ æ€»å…±ä¿å­˜ {file_idx} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # ä¿å­˜å…ƒä¿¡æ¯ - ä¼ é€’æ­£ç¡®çš„metaæ ¹ç›®å½•
        root_meta_dir = self.output_dir / 'meta'
        self._save_metadata(root_meta_dir, episodes_df, tasks_df)
        
        return self.output_dir
    
    def _save_frame_batch(self, frame_records: List[Dict], file_path: Path):
        """
        ä¿å­˜ä¸€æ‰¹å¸§æ•°æ®ä¸ºparquetæ–‡ä»¶ï¼Œä½¿ç”¨LeRobotçš„æ–¹å¼ç¼–ç å›¾åƒ
        """
        from datasets import Dataset, Features, Image as HFImage, Sequence, Value
        
        def to_numpy(val):
            if hasattr(val, 'detach'):
                val = val.detach()
            if hasattr(val, 'cpu'):
                val = val.cpu()
            if hasattr(val, 'numpy'):
                return val.numpy()
            if isinstance(val, list):
                return np.array(val)
            return val
        
        # å°†Tensorå›¾åƒè½¬æ¢ä¸ºPIL Image
        def tensor_to_pil(tensor_data):
            if hasattr(tensor_data, 'cpu'):
                tensor_data = tensor_data.cpu()
            if hasattr(tensor_data, 'numpy'):
                tensor_data = tensor_data.numpy()
            
            # CHW -> HWC
            if tensor_data.ndim == 3 and tensor_data.shape[0] == 3:
                tensor_data = tensor_data.transpose(1, 2, 0)
            
            # 0-1 float -> 0-255 uint8
            if tensor_data.dtype != np.uint8:
                if tensor_data.max() <= 1.0:
                    tensor_data = (tensor_data * 255).astype(np.uint8)
                else:
                    tensor_data = tensor_data.astype(np.uint8)
            
            return Image.fromarray(tensor_data)
        
        # å‡†å¤‡æ•°æ®
        data = {
            'observation.images.image': [tensor_to_pil(f['observation.images.image']) for f in frame_records],
            'observation.images.image2': [tensor_to_pil(f['observation.images.image2']) for f in frame_records],
            'observation.state': [to_numpy(f['observation.state']).tolist() for f in frame_records],
            'action': [to_numpy(f['action']).tolist() for f in frame_records],
            'timestamp': [float(to_numpy(f['timestamp'])) for f in frame_records],
            # æ·»åŠ å…ƒæ•°æ®å­—æ®µ
            'episode_index': [int(to_numpy(f['episode_index'])) for f in frame_records],
            'frame_index': [int(to_numpy(f['frame_index'])) for f in frame_records],
            'index': [int(to_numpy(f['index'])) for f in frame_records],
            'task_index': [int(to_numpy(f['task_index'])) for f in frame_records],
        }
        
        # å®šä¹‰HuggingFace Datasetçš„Features
        features = Features({
            'observation.images.image': HFImage(),
            'observation.images.image2': HFImage(),
            'observation.state': Sequence(Value('float32')),
            'action': Sequence(Value('float32')),
            'timestamp': Value('float32'),
            # æ·»åŠ å…ƒæ•°æ®å­—æ®µ
            'episode_index': Value('int64'),
            'frame_index': Value('int64'),
            'index': Value('int64'),
            'task_index': Value('int64'),
        })
        
        # åˆ›å»ºHuggingFace Dataset
        dataset = Dataset.from_dict(data, features=features)
        
        # å†™å…¥Parquetæ–‡ä»¶
        dataset.to_parquet(file_path)
    
    @staticmethod
    def _save_metadata(meta_dir: Path, episodes_df: pd.DataFrame, tasks_df: pd.DataFrame):
        """
        ä¿å­˜å…ƒä¿¡æ¯æ–‡ä»¶
        """
        print(f"  ğŸ“ å¼€å§‹ä¿å­˜å…ƒä¿¡æ¯åˆ° {meta_dir}...")
        
        # ä¿å­˜info.json - å®Œæ•´çš„LeRobotæ ¼å¼
        info = {
            'codebase_version': 'v3.0',
            'robot_type': 'Panda 7-DOF',
            'total_episodes': int(len(episodes_df)),
            'total_frames': int(episodes_df['length'].sum()),
            'total_tasks': int(len(tasks_df)),
            'chunks_size': 1000,
            'fps': 10.0,
            'splits': {
                'train': f"0:{len(episodes_df)}"
            },
            'data_path': 'data/episode_{chunk_index}/segment_{file_index}.parquet',
            'features': {
                'observation.images.image': {
                    'dtype': 'image',
                    'shape': [256, 256, 3],
                    'names': ['height', 'width', 'channel'],
                    'fps': 10.0
                },
                'observation.images.image2': {
                    'dtype': 'image',
                    'shape': [256, 256, 3],
                    'names': ['height', 'width', 'channel'],
                    'fps': 10.0
                },
                'observation.state': {
                    'dtype': 'float32',
                    'shape': [8],
                    'names': ['state'],
                    'fps': 10.0
                },
                'action': {
                    'dtype': 'float32',
                    'shape': [7],
                    'names': ['actions'],
                    'fps': 10.0
                },
                'timestamp': {
                    'dtype': 'float32',
                    'shape': [1],
                    'names': None,
                    'fps': 10.0
                },
                'episode_index': {
                    'dtype': 'int64',
                    'shape': [1],
                    'names': None,
                    'fps': 10.0
                },
                'frame_index': {
                    'dtype': 'int64',
                    'shape': [1],
                    'names': None,
                    'fps': 10.0
                },
                'index': {
                    'dtype': 'int64',
                    'shape': [1],
                    'names': None,
                    'fps': 10.0
                },
                'task_index': {
                    'dtype': 'int64',
                    'shape': [1],
                    'names': None,
                    'fps': 10.0
                }
            }
        }
        
        with open(meta_dir / 'info.json', 'w') as f:
            json.dump(info, f, indent=2, default=str)
        
        # ä¿å­˜stats.json
        stats = {
            'total_episodes': int(len(episodes_df)),
            'total_frames': int(episodes_df['length'].sum()),
            'total_tasks': int(len(tasks_df)),
            'average_frames_per_episode': float(episodes_df['length'].mean()),
            'min_frames_per_episode': int(episodes_df['length'].min()),
            'max_frames_per_episode': int(episodes_df['length'].max()),
        }
        
        with open(meta_dir / 'stats.json', 'w') as f:
            json.dump(stats, f, indent=2, default=str)
        
        print(f"  âœ“ ä¿å­˜å…ƒä¿¡æ¯æ–‡ä»¶")


def cut_and_convert_dataset(dataset,
                           frame_ranges: List[Dict],
                           output_dir: Optional[str],
                           save_mode: str = 'lerobot',
                           max_episodes: Optional[int] = None,
                           batch_size: int = 100,
                           streaming: bool = True,
                           insert_placeholders: bool = False,
                           placeholder_action_value: float = -999.0,
                           repo_id: Optional[str] = None,
                           robot_type: str = "panda",
                           fps: float = 10.0,
                           use_official_api: bool = True) -> Path:
    """
    å®Œæ•´çš„æ•°æ®é›†è£å‰ªå’Œè½¬æ¢æµç¨‹
    
    Args:
        dataset: åŸå§‹LeRobotæ•°æ®é›†
        frame_ranges: å¸§èŒƒå›´åˆ—è¡¨ï¼ˆåŒ…å«new_taskå­—æ®µï¼‰
        output_dir: è¾“å‡ºç›®å½•
        save_mode: ä¿å­˜æ¨¡å¼ 'image'ï¼ˆå›¾ç‰‡ï¼‰, 'lerobot'ï¼ˆParquetï¼‰, æˆ– 'both'ï¼ˆä¸¤è€…ï¼‰
        max_episodes: æœ€å¤šä¿å­˜çš„episodeæ•°é‡
        batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯æ¬¡å¤„ç†å¤šå°‘ä¸ªepisodeï¼‰
        streaming: æ˜¯å¦ä½¿ç”¨æµå¼å¤„ç†ï¼ˆæ¨èï¼ŒèŠ‚çœå†…å­˜ï¼‰
        insert_placeholders: æ˜¯å¦åœ¨åŒä¸€chunkçš„ä¸åŒsegmentsä¹‹é—´ç‰©ç†æ’å…¥placeholderï¼ˆæ–¹æ¡ˆ3ï¼‰
        placeholder_action_value: placeholderçš„actionå€¼ï¼ˆé»˜è®¤-999.0ï¼‰
        repo_id: HuggingFace repo IDï¼ˆç”¨äºå®˜æ–¹APIï¼‰
        robot_type: æœºå™¨äººç±»å‹ï¼ˆé»˜è®¤"panda"ï¼‰
        fps: é‡‡æ ·é¢‘ç‡ï¼ˆé»˜è®¤10.0ï¼‰
        use_official_api: æ˜¯å¦ä½¿ç”¨LeRobotå®˜æ–¹APIï¼ˆæ¨èï¼‰
        
    Returns:
        è¾“å‡ºç›®å½•è·¯å¾„
    """
    cutter = DatasetCutter(output_dir, save_mode=save_mode, batch_size=batch_size,
                          insert_placeholders=insert_placeholders,
                          placeholder_action_value=placeholder_action_value,
                          repo_id=repo_id, robot_type=robot_type, fps=fps,
                          use_official_api=use_official_api)
    
    # ä½¿ç”¨æµå¼å¤„ç†ï¼ˆæ¨èï¼‰
    if streaming and save_mode in ['lerobot', 'both']:
        print(f"\nğŸ’¡ ä½¿ç”¨æµå¼å¤„ç†æ¨¡å¼ï¼ˆæ‰¹å¤§å°: {batch_size}ï¼‰")
        output_path = cutter.save_as_lerobot_format_streaming(dataset, frame_ranges, max_episodes)
        
        # å¦‚æœéœ€è¦åŒæ—¶ä¿å­˜å›¾ç‰‡æ ¼å¼
        if save_mode == 'both':
            print("\nğŸ“¦ é¢å¤–ä¿å­˜å›¾ç‰‡æ ¼å¼...\n")
            # å›¾ç‰‡æ ¼å¼ä¹Ÿä½¿ç”¨æ‰¹å¤„ç†
            for batch_start in range(0, len(frame_ranges), batch_size):
                batch_end = min(batch_start + batch_size, len(frame_ranges))
                extracted_data = cutter.extract_frames_batch(dataset, frame_ranges, batch_start, batch_end)
                episodes_data = cutter.organize_by_episode(extracted_data)
                cutter.save_as_image_format(episodes_data, frame_ranges[batch_start:batch_end], max_episodes)
                del extracted_data, episodes_data
                import gc
                gc.collect()
    else:
        # æ—§æ–¹å¼ï¼šä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ï¼ˆä¸æ¨èï¼Œä½†ä¿ç•™å…¼å®¹æ€§ï¼‰
        print(f"\nâš ï¸  ä½¿ç”¨ä¼ ç»Ÿå¤„ç†æ¨¡å¼ï¼ˆä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ï¼‰")
        extracted_data = cutter.extract_frames_batch(dataset, frame_ranges, 0, len(frame_ranges))
        episodes_data = cutter.organize_by_episode(extracted_data)
        
        if save_mode == 'image':
            output_path = cutter.save_as_image_format(episodes_data, frame_ranges, max_episodes)
        elif save_mode == 'lerobot':
            output_path = cutter.save_as_lerobot_format(episodes_data, frame_ranges, max_episodes)
        elif save_mode == 'both':
            print("\nğŸ“¦ ä¿å­˜ä¸¤ç§æ ¼å¼...\n")
            cutter.save_as_image_format(episodes_data, frame_ranges, max_episodes)
            output_path = cutter.save_as_lerobot_format(episodes_data, frame_ranges, max_episodes)
        else:
            raise ValueError(f"Unknown save_mode: {save_mode}. Use 'image', 'lerobot', or 'both'")
    
    return output_path


if __name__ == '__main__':
    print("Dataset Cutter Module")
