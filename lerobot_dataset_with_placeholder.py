#!/usr/bin/env python3
"""
å¸¦å ä½ç¬¦çš„ LeRobot Dataset åŒ…è£…å™¨

åŠŸèƒ½ï¼š
1. åœ¨åŒä¸€ episode çš„ä¸åŒ segment ä¹‹é—´è‡ªåŠ¨æ’å…¥å ä½ç¬¦å¸§
2. å ä½ç¬¦å¸§æ ‡è®°ä¸º is_placeholder=Trueï¼ŒåŒ…å«ç‰¹æ®Šæ ‡è¯†
3. ä¸åŒ episode ä¹‹é—´ä¸æ’å…¥å ä½ç¬¦
4. å®Œå…¨å…¼å®¹åŸå§‹ LeRobotDataset çš„æ‰€æœ‰æ¥å£

ä½¿ç”¨åœºæ™¯ï¼š
é€‚ç”¨äº motion_planning ç³»ç»Ÿï¼Œéœ€è¦æ˜ç¡®æ ‡è¯†åŒä¸€ episode å†…çš„è·³è·ƒåŠ¨ä½œè¾¹ç•Œ
"""

import torch
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Any, List
from collections import defaultdict
import json
import copy

try:
    from lerobot.datasets.lerobot_dataset import LeRobotDataset
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… lerobot: pip install lerobot")
    raise


class AdjustedEpisodesWrapper:
    """
    EpisodesåŒ…è£…å™¨ï¼ŒåŠ¨æ€è°ƒæ•´dataset_from_indexå’Œdataset_to_index
    """
    def __init__(self, original_episodes, adjusted_ranges):
        self._original_episodes = original_episodes
        self._adjusted_ranges = adjusted_ranges
    
    def __len__(self):
        return len(self._original_episodes)
    
    def __getitem__(self, idx):
        """è¿”å›è°ƒæ•´åçš„episodeå…ƒæ•°æ®"""
        original_ep = self._original_episodes[idx]
        
        if idx in self._adjusted_ranges:
            # åˆ›å»ºä¸€ä¸ªæ–°å­—å…¸ï¼ŒåŒ…å«è°ƒæ•´åçš„ç´¢å¼•
            adjusted_ep = dict(original_ep)
            adjusted_ep['dataset_from_index'] = self._adjusted_ranges[idx]['dataset_from_index']
            adjusted_ep['dataset_to_index'] = self._adjusted_ranges[idx]['dataset_to_index']
            return adjusted_ep
        
        return original_ep
    
    def __iter__(self):
        """æ”¯æŒè¿­ä»£"""
        for idx in range(len(self)):
            yield self[idx]


class AdjustedMetadataWrapper:
    """
    MetadataåŒ…è£…å™¨ï¼Œè¿”å›è°ƒæ•´åçš„episodes
    """
    def __init__(self, original_meta, adjusted_ranges):
        self._original_meta = original_meta
        self._adjusted_episodes = AdjustedEpisodesWrapper(original_meta.episodes, adjusted_ranges)
    
    @property
    def episodes(self):
        """è¿”å›è°ƒæ•´åçš„episodes"""
        return self._adjusted_episodes
    
    def __getattr__(self, name):
        """å…¶ä»–å±æ€§ç›´æ¥ä»åŸå§‹metaè·å–"""
        return getattr(self._original_meta, name)


class LeRobotDatasetWithPlaceholder:
    """
    LeRobot Dataset çš„åŒ…è£…å™¨ï¼Œåœ¨åŒä¸€ episode çš„ä¸åŒ segment ä¹‹é—´æ’å…¥å ä½ç¬¦
    
    å ä½ç¬¦ç‰¹æ€§ï¼š
    - is_placeholder=True æ ‡è®°
    - action å…¨ä¸º -999 (ç‰¹æ®Šæ ‡è¯†å€¼)
    - observation ä½¿ç”¨å‰ä¸€å¸§çš„æ•°æ®
    - episode_index å’Œ task ä¿æŒä¸å˜
    """
    
    def __init__(
        self,
        repo_id: str,
        root: str,
        placeholder_action_value: float = -999.0,
        **kwargs
    ):
        """
        åˆå§‹åŒ–å¸¦å ä½ç¬¦çš„æ•°æ®é›†
        
        Args:
            repo_id: æ•°æ®é›†IDï¼ˆé€šå¸¸æ˜¯æ•°æ®é›†åç§°ï¼‰
            root: æ•°æ®é›†æ ¹ç›®å½•
            placeholder_action_value: å ä½ç¬¦çš„actionå€¼ï¼ˆé»˜è®¤-999ï¼‰
            **kwargs: ä¼ é€’ç»™åŸå§‹ LeRobotDataset çš„å…¶ä»–å‚æ•°
        """
        print(f"ğŸ”§ åˆå§‹åŒ–å¸¦å ä½ç¬¦çš„ LeRobot Dataset...")
        print(f"   repo_id: {repo_id}")
        print(f"   root: {root}")
        
        # åŠ è½½åŸå§‹æ•°æ®é›†
        self.original_dataset = LeRobotDataset(repo_id=repo_id, root=root, **kwargs)
        self.placeholder_value = placeholder_action_value
        self.root = Path(root)
        
        # åˆ†æ episode å’Œ segment ç»“æ„
        self._analyze_episode_structure()
        
        # æ„å»ºç´¢å¼•æ˜ å°„ï¼ˆåŸå§‹ç´¢å¼• -> æ–°ç´¢å¼•ï¼Œæ’å…¥å ä½ç¬¦åï¼‰
        self._build_index_mapping()
        
        # æ„å»ºè°ƒæ•´åçš„metaä¿¡æ¯ï¼ˆæ–¹æ¡ˆ1ï¼šåŠ¨æ€æ›´æ–°metaï¼‰
        self._build_adjusted_meta()
        
        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
        print(f"   åŸå§‹å¸§æ•°: {len(self.original_dataset)}")
        print(f"   æ–°å¢å ä½ç¬¦: {self.num_placeholders}")
        print(f"   æ€»å¸§æ•°: {len(self)}")
        print(f"   Episodeæ•°: {self.num_episodes}")
        
    def _analyze_episode_structure(self):
        """åˆ†ææ¯ä¸ª episode åŒ…å«å“ªäº› segmentï¼ˆæ•°æ®æ–‡ä»¶ï¼‰"""
        print("ğŸ” åˆ†æ episode ç»“æ„...")
        
        # è¯»å– episode å…ƒæ•°æ®
        episodes_meta = self.original_dataset.meta.episodes
        
        # æŒ‰ chunk_index åˆ†ç»„ï¼ˆåŒä¸€ä¸ªåŸå§‹ episode çš„ä¸åŒ segmentï¼‰
        # chunk_index è¡¨ç¤ºåŸå§‹çš„ episodeï¼Œå¤šä¸ª episode_index å¯èƒ½å±äºåŒä¸€ä¸ª chunk_index
        self.episode_segments = defaultdict(list)
        
        for ep_idx in range(len(episodes_meta)):
            ep_meta = episodes_meta[ep_idx]
            episode_index = ep_meta['episode_index']
            chunk_index = ep_meta['data/chunk_index']
            file_index = ep_meta['data/file_index']
            from_idx = ep_meta['dataset_from_index']
            to_idx = ep_meta['dataset_to_index']
            
            # ä½¿ç”¨ chunk_index ä½œä¸ºåˆ†ç»„é”®ï¼ˆè¡¨ç¤ºåŒä¸€ä¸ªåŸå§‹ episodeï¼‰
            self.episode_segments[chunk_index].append({
                'episode_index': episode_index,
                'file_index': file_index,
                'chunk_index': chunk_index,
                'from_idx': from_idx,
                'to_idx': to_idx,
                'length': to_idx - from_idx + 1
            })
        
        # å¯¹æ¯ä¸ªåŸå§‹ episode çš„ segment æŒ‰ from_idx æ’åº
        for chunk_idx in self.episode_segments:
            self.episode_segments[chunk_idx].sort(key=lambda x: x['from_idx'])
        
        # ç»Ÿè®¡éœ€è¦æ’å…¥çš„å ä½ç¬¦æ•°é‡
        self.placeholder_positions = []  # å­˜å‚¨æ‰€æœ‰å ä½ç¬¦çš„æ’å…¥ä½ç½®
        
        for chunk_idx, segments in self.episode_segments.items():
            if len(segments) > 1:
                # æœ‰å¤šä¸ª segmentï¼Œéœ€è¦åœ¨ç›¸é‚» segment ä¹‹é—´æ’å…¥å ä½ç¬¦
                for i in range(len(segments) - 1):
                    insert_after_idx = segments[i]['to_idx']  # åœ¨ç¬¬ i ä¸ª segment çš„æœ€åä¸€å¸§ä¹‹åæ’å…¥
                    next_segment_first_idx = segments[i+1]['from_idx']
                    
                    self.placeholder_positions.append({
                        'chunk_index': chunk_idx,  # åŸå§‹ episode
                        'episode_index': segments[i]['episode_index'],  # ç¬¬ i ä¸ª segment çš„ episode_index
                        'next_episode_index': segments[i+1]['episode_index'],  # ç¬¬ i+1 ä¸ª segment çš„ episode_index
                        'insert_after_original_idx': insert_after_idx,
                        'segment_boundary': (i, i+1)  # åœ¨ç¬¬iå’Œç¬¬i+1ä¸ªsegmentä¹‹é—´
                    })
        
        self.num_placeholders = len(self.placeholder_positions)
        
        print(f"   åˆ†æå®Œæˆ:")
        print(f"   - åŸå§‹ Episodes (chunk_index): {len(self.episode_segments)}")
        print(f"   - åˆ‡åˆ†åçš„ Segments: {sum(len(segs) for segs in self.episode_segments.values())}")
        print(f"   - å¤š Segment Episodes: {sum(1 for segs in self.episode_segments.values() if len(segs) > 1)}")
        print(f"   - éœ€æ’å…¥å ä½ç¬¦: {self.num_placeholders} ä¸ª")
        
        # æ‰“å°è¯¦ç»†çš„ segment ç»“æ„
        for chunk_idx, segments in sorted(self.episode_segments.items()):
            if len(segments) > 1:
                print(f"   åŸå§‹ Episode {chunk_idx} (chunk_index): {len(segments)} segments")
                for i, seg in enumerate(segments):
                    print(f"      Segment {i} (episode_index={seg['episode_index']}): frames {seg['from_idx']}-{seg['to_idx']} (length={seg['length']})")
    
    def _build_index_mapping(self):
        """
        æ„å»ºæ–°æ—§ç´¢å¼•çš„æ˜ å°„å…³ç³»
        
        æ–°ç´¢å¼• = åŸå§‹ç´¢å¼• + ä¹‹å‰æ’å…¥çš„å ä½ç¬¦æ•°é‡
        """
        # å¯¹å ä½ç¬¦ä½ç½®æŒ‰åŸå§‹ç´¢å¼•æ’åº
        self.placeholder_positions.sort(key=lambda x: x['insert_after_original_idx'])
        
        # è®¡ç®—æ¯ä¸ªæ–°ç´¢å¼•å¯¹åº”çš„åŸå§‹ç´¢å¼•ï¼ˆæˆ–å ä½ç¬¦æ ‡è®°ï¼‰
        self.new_to_original_idx = []  # æ–°ç´¢å¼• -> (åŸå§‹ç´¢å¼•, is_placeholder)
        
        original_idx = 0
        placeholder_idx = 0
        
        while original_idx < len(self.original_dataset):
            # æ·»åŠ å½“å‰åŸå§‹å¸§
            self.new_to_original_idx.append((original_idx, False))
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨è¿™ä¸ªä½ç½®åæ’å…¥å ä½ç¬¦
            if placeholder_idx < len(self.placeholder_positions):
                placeholder_info = self.placeholder_positions[placeholder_idx]
                if original_idx == placeholder_info['insert_after_original_idx']:
                    # æ’å…¥å ä½ç¬¦
                    self.new_to_original_idx.append((-1, True, placeholder_info))
                    placeholder_idx += 1
            
            original_idx += 1
        
        print(f"ğŸ—ºï¸  ç´¢å¼•æ˜ å°„æ„å»ºå®Œæˆ: {len(self.new_to_original_idx)} ä¸ªæ–°ç´¢å¼•")
    
    def _build_adjusted_meta(self):
        """
        æ„å»ºè°ƒæ•´åçš„metaä¿¡æ¯ï¼ˆæ–¹æ¡ˆ1å®ç°ï¼‰
        
        æ ¹æ®placeholderçš„æ’å…¥ä½ç½®ï¼Œé‡æ–°è®¡ç®—æ‰€æœ‰episodeçš„dataset_from_indexå’Œdataset_to_index
        ä½¿metaä¿¡æ¯ä¸å®é™…æ•°æ®ç´¢å¼•ä¿æŒä¸€è‡´
        """
        print("ğŸ“ æ„å»ºè°ƒæ•´åçš„metaä¿¡æ¯...")
        
        # æ„å»ºåŸå§‹ç´¢å¼•åˆ°æ–°ç´¢å¼•çš„æ˜ å°„è¡¨
        # original_to_new[original_idx] = new_idx
        self.original_to_new_idx = {}
        for new_idx, mapping in enumerate(self.new_to_original_idx):
            if not mapping[1]:  # ä¸æ˜¯placeholder
                original_idx = mapping[0]
                self.original_to_new_idx[original_idx] = new_idx
        
        # ä¸ºæ¯ä¸ªepisodeå­˜å‚¨è°ƒæ•´åçš„ç´¢å¼•
        self._adjusted_episode_ranges = {}
        episodes_meta = self.original_dataset.meta.episodes
        
        for ep_idx in range(len(episodes_meta)):
            ep_meta = episodes_meta[ep_idx]
            original_from = ep_meta['dataset_from_index']
            original_to = ep_meta['dataset_to_index']
            
            # ä½¿ç”¨æ˜ å°„è¡¨ç›´æ¥è·å–è°ƒæ•´åçš„ç´¢å¼•
            adjusted_from = self.original_to_new_idx.get(original_from, original_from)
            adjusted_to = self.original_to_new_idx.get(original_to, original_to)
            
            # å­˜å‚¨è°ƒæ•´åçš„èŒƒå›´
            self._adjusted_episode_ranges[ep_idx] = {
                'dataset_from_index': adjusted_from,
                'dataset_to_index': adjusted_to,
                'offset': adjusted_from - original_from
            }
            
            # è°ƒè¯•ä¿¡æ¯ï¼ˆå‰5ä¸ªepisodeï¼‰
            if ep_idx < 5:
                offset = adjusted_from - original_from
                print(f"   Episode {ep_idx}: {original_from:>3}-{original_to:<3} -> {adjusted_from:>3}-{adjusted_to:<3} (åç§»+{offset})")
        
        print(f"âœ… Metaä¿¡æ¯æ›´æ–°å®Œæˆï¼Œæ‰€æœ‰episodeçš„ç´¢å¼•å·²è°ƒæ•´")
    
    def _create_placeholder_frame(self, previous_frame: Dict[str, Any], episode_index: int) -> Dict[str, Any]:
        """
        åˆ›å»ºå ä½ç¬¦å¸§
        
        Args:
            previous_frame: å‰ä¸€å¸§çš„æ•°æ®ï¼ˆç”¨äºå¤åˆ¶è§‚æµ‹ï¼‰
            episode_index: å½“å‰ episode ç´¢å¼•
            
        Returns:
            å ä½ç¬¦å¸§æ•°æ®
        """
        placeholder = {}
        
        # å¤åˆ¶è§‚æµ‹æ•°æ®ï¼ˆå›¾åƒå’ŒçŠ¶æ€ï¼‰
        for key in previous_frame.keys():
            if key.startswith('observation.'):
                placeholder[key] = previous_frame[key].clone() if torch.is_tensor(previous_frame[key]) else previous_frame[key]
        
        # è®¾ç½®ç‰¹æ®Šçš„ action å€¼
        action_shape = previous_frame['action'].shape
        placeholder['action'] = torch.full(action_shape, self.placeholder_value, dtype=previous_frame['action'].dtype)
        
        # å¤åˆ¶å…ƒæ•°æ®ï¼Œä½†æ ‡è®°ä¸ºå ä½ç¬¦
        if 'timestamp' in previous_frame:
            placeholder['timestamp'] = previous_frame['timestamp']
        if 'episode_index' in previous_frame:
            placeholder['episode_index'] = previous_frame['episode_index']
        if 'task_index' in previous_frame:
            placeholder['task_index'] = previous_frame['task_index']
        if 'task' in previous_frame:
            placeholder['task'] = previous_frame['task']
        
        # æ·»åŠ å ä½ç¬¦æ ‡è®°
        placeholder['is_placeholder'] = torch.tensor(True)
        placeholder['frame_index'] = torch.tensor(-1)  # å ä½ç¬¦æ²¡æœ‰æœ‰æ•ˆçš„ frame_index
        
        return placeholder
    
    def __len__(self) -> int:
        """è¿”å›æ€»å¸§æ•°ï¼ˆåŒ…æ‹¬å ä½ç¬¦ï¼‰"""
        return len(self.new_to_original_idx)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šç´¢å¼•çš„å¸§æ•°æ®
        
        Args:
            idx: æ–°ç´¢å¼•ï¼ˆåŒ…å«å ä½ç¬¦åçš„ç´¢å¼•ï¼‰
            
        Returns:
            å¸§æ•°æ®å­—å…¸
        """
        if idx < 0 or idx >= len(self):
            raise IndexError(f"Index {idx} out of range [0, {len(self)})")
        
        mapping = self.new_to_original_idx[idx]
        
        if mapping[1]:  # is_placeholder
            # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦
            placeholder_info = mapping[2]
            chunk_index = placeholder_info['chunk_index']
            episode_index = placeholder_info['episode_index']
            
            # è·å–å‰ä¸€å¸§æ•°æ®ï¼ˆç”¨äºå¤åˆ¶è§‚æµ‹ï¼‰
            previous_original_idx = placeholder_info['insert_after_original_idx']
            previous_frame = self.original_dataset[previous_original_idx]
            
            # åˆ›å»ºå ä½ç¬¦å¸§
            return self._create_placeholder_frame(previous_frame, episode_index)
        else:
            # è¿™æ˜¯åŸå§‹æ•°æ®å¸§
            original_idx = mapping[0]
            frame = self.original_dataset[original_idx]
            
            # æ·»åŠ æ ‡è®°ï¼šä¸æ˜¯å ä½ç¬¦
            frame['is_placeholder'] = torch.tensor(False)
            
            return frame
    
    @property
    def num_episodes(self) -> int:
        """è¿”å›åŸå§‹ episode æ€»æ•°ï¼ˆæŒ‰ chunk_index è®¡ç®—ï¼‰"""
        return len(self.episode_segments)
    
    @property
    def num_segments(self) -> int:
        """è¿”å›åˆ‡åˆ†åçš„ segment æ€»æ•°ï¼ˆæŒ‰ episode_index è®¡ç®—ï¼‰"""
        return self.original_dataset.num_episodes
    
    @property
    def meta(self):
        """è¿”å›è°ƒæ•´åçš„å…ƒæ•°æ®ï¼ˆåŒ…å«placeholderåç§»ï¼‰"""
        if not hasattr(self, '_meta_wrapper'):
            self._meta_wrapper = AdjustedMetadataWrapper(
                self.original_dataset.meta,
                self._adjusted_episode_ranges
            )
        return self._meta_wrapper
    
    @property
    def original_meta(self):
        """è¿”å›åŸå§‹æ•°æ®é›†çš„å…ƒæ•°æ®ï¼ˆæœªè°ƒæ•´ï¼‰"""
        return self.original_dataset.meta
    
    @property
    def hf_dataset(self):
        """è¿”å›åŸå§‹æ•°æ®é›†çš„ HuggingFace Dataset"""
        return self.original_dataset.hf_dataset
    
    def get_episode_info(self, chunk_idx: int) -> Dict:
        """
        è·å–æŒ‡å®šåŸå§‹ episodeï¼ˆchunk_indexï¼‰çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            chunk_idx: Chunk ç´¢å¼•ï¼ˆåŸå§‹ episodeï¼‰
            
        Returns:
            åŒ…å« segment ä¿¡æ¯å’Œå ä½ç¬¦ä½ç½®çš„å­—å…¸
        """
        if chunk_idx not in self.episode_segments:
            raise ValueError(f"Chunk {chunk_idx} not found")
        
        segments = self.episode_segments[chunk_idx]
        
        # æ‰¾å‡ºè¿™ä¸ª chunk ä¸­çš„å ä½ç¬¦ä½ç½®
        placeholders = [p for p in self.placeholder_positions if p['chunk_index'] == chunk_idx]
        
        return {
            'chunk_index': chunk_idx,
            'num_segments': len(segments),
            'segments': segments,
            'num_placeholders': len(placeholders),
            'placeholder_positions': placeholders
        }
    
    def print_episode_structure(self, chunk_idx: Optional[int] = None):
        """
        æ‰“å° episode ç»“æ„ä¿¡æ¯
        
        Args:
            chunk_idx: æŒ‡å®šåŸå§‹ episodeï¼ˆchunk_indexï¼‰ï¼ŒNone åˆ™æ‰“å°æ‰€æœ‰
        """
        if chunk_idx is not None:
            chunks = [chunk_idx]
        else:
            chunks = sorted(self.episode_segments.keys())
        
        print("\n" + "="*80)
        print("ğŸ“Š Episode ç»“æ„ä¿¡æ¯")
        print("="*80)
        
        for ch_idx in chunks:
            info = self.get_episode_info(ch_idx)
            print(f"\nåŸå§‹ Episode {ch_idx} (chunk_index={ch_idx}):")
            print(f"  åˆ‡åˆ†ä¸º {info['num_segments']} ä¸ª Segments:")
            
            for i, seg in enumerate(info['segments']):
                print(f"    Segment {i} (episode_index={seg['episode_index']}):")
                print(f"      åŸå§‹å¸§èŒƒå›´: {seg['from_idx']}-{seg['to_idx']}")
                print(f"      å¸§æ•°: {seg['length']}")
                print(f"      æ–‡ä»¶: data/episode_{seg['chunk_index']}/segment_{seg['file_index']}.parquet")
            
            if info['num_placeholders'] > 0:
                print(f"  å ä½ç¬¦: {info['num_placeholders']} ä¸ª")
                for p in info['placeholder_positions']:
                    print(f"    åœ¨åŸå§‹ç´¢å¼• {p['insert_after_original_idx']} åæ’å…¥")
                    print(f"    (Segment {p['segment_boundary'][0]} [ep={p['episode_index']}] -> Segment {p['segment_boundary'][1]} [ep={p['next_episode_index']}])")
        
        print("="*80 + "\n")
    
    def verify_placeholders(self, num_samples: int = 5):
        """
        éªŒè¯å ä½ç¬¦æ˜¯å¦æ­£ç¡®æ’å…¥
        
        Args:
            num_samples: æ£€æŸ¥çš„æ ·æœ¬æ•°é‡
        """
        print("\n" + "="*80)
        print("ğŸ” éªŒè¯å ä½ç¬¦")
        print("="*80)
        
        # æ‰¾å‡ºæ‰€æœ‰å ä½ç¬¦çš„æ–°ç´¢å¼•
        placeholder_indices = [i for i, mapping in enumerate(self.new_to_original_idx) if mapping[1]]
        
        if not placeholder_indices:
            print("âœ“ æ²¡æœ‰å ä½ç¬¦éœ€è¦éªŒè¯")
            return
        
        print(f"æ€»å ä½ç¬¦æ•°: {len(placeholder_indices)}")
        print(f"\næ£€æŸ¥å‰ {min(num_samples, len(placeholder_indices))} ä¸ªå ä½ç¬¦:\n")
        
        for i, placeholder_idx in enumerate(placeholder_indices[:num_samples]):
            frame = self[placeholder_idx]
            prev_frame = self[placeholder_idx - 1] if placeholder_idx > 0 else None
            next_frame = self[placeholder_idx + 1] if placeholder_idx < len(self) - 1 else None
            
            print(f"å ä½ç¬¦ #{i+1} (æ–°ç´¢å¼• {placeholder_idx}):")
            print(f"  is_placeholder: {frame['is_placeholder'].item()}")
            print(f"  action: {frame['action'][:3].tolist()}... (æœŸæœ›å…¨ä¸º {self.placeholder_value})")
            print(f"  episode_index: {frame['episode_index'].item()}")
            
            if prev_frame:
                print(f"  å‰ä¸€å¸§ (ç´¢å¼• {placeholder_idx-1}):")
                print(f"    is_placeholder: {prev_frame['is_placeholder'].item()}")
                print(f"    episode_index: {prev_frame['episode_index'].item()}")
                print(f"    action[:3]: {prev_frame['action'][:3].tolist()}")
            
            if next_frame:
                print(f"  åä¸€å¸§ (ç´¢å¼• {placeholder_idx+1}):")
                print(f"    is_placeholder: {next_frame['is_placeholder'].item()}")
                print(f"    episode_index: {next_frame['episode_index'].item()}")
                print(f"    action[:3]: {next_frame['action'][:3].tolist()}")
            
            # éªŒè¯ action æ˜¯å¦å…¨ä¸ºå ä½ç¬¦å€¼
            is_valid = torch.all(frame['action'] == self.placeholder_value).item()
            print(f"  âœ“ Action éªŒè¯: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}")
            print()
        
        print("="*80 + "\n")


def demo():
    """æ¼”ç¤ºç”¨æ³•"""
    import sys
    
    # ç¤ºä¾‹ï¼šåŠ è½½æ•°æ®é›†
    dataset_path = "/home/dongyingyibadao/data_dealer_auto/cut_dataset"
    
    print("="*80)
    print("ğŸš€ LeRobot Dataset with Placeholder - æ¼”ç¤º")
    print("="*80 + "\n")
    
    # 1. åŠ è½½æ•°æ®é›†
    dataset = LeRobotDatasetWithPlaceholder(
        repo_id='cut_dataset',
        root=dataset_path,
        placeholder_action_value=-999.0
    )
    
    # 2. æ‰“å° episode ç»“æ„
    dataset.print_episode_structure()
    
    # 3. éªŒè¯å ä½ç¬¦
    dataset.verify_placeholders(num_samples=3)
    
    # 4. è®¿é—®æ•°æ®ç¤ºä¾‹
    print("\n" + "="*80)
    print("ğŸ“– æ•°æ®è®¿é—®ç¤ºä¾‹")
    print("="*80 + "\n")
    
    for i in range(min(10, len(dataset))):
        frame = dataset[i]
        placeholder_mark = "ğŸ”¶ [PLACEHOLDER]" if frame['is_placeholder'].item() else ""
        action_str = f"[{frame['action'][0]:.2f}, {frame['action'][1]:.2f}, ...]" if not frame['is_placeholder'].item() else f"[{frame['action'][0]:.1f}, {frame['action'][1]:.1f}, ...]"
        
        print(f"ç´¢å¼• {i:3d}: Episode {frame['episode_index'].item():2d} | Action: {action_str} {placeholder_mark}")
    
    print("\n" + "="*80)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("="*80)


if __name__ == '__main__':
    demo()
