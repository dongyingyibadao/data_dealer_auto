# LeRobot Dataset with Placeholder

ä¸º motion_planning ç³»ç»Ÿæä¾›çš„å¢å¼ºå‹ LeRobot Dataset åŒ…è£…å™¨ã€‚

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

1. **è‡ªåŠ¨æ’å…¥å ä½ç¬¦**ï¼šåœ¨åŒä¸€åŸå§‹ episode çš„ä¸åŒ segment ä¹‹é—´è‡ªåŠ¨æ’å…¥å ä½ç¬¦å¸§
2. **è·³è·ƒæ ‡è¯†**ï¼šå ä½ç¬¦æ˜ç¡®æ ‡è®°åŠ¨ä½œçš„è·³è·ƒè¾¹ç•Œï¼Œå¸®åŠ©æœºå™¨äººç†è§£éè¿ç»­åŠ¨ä½œ
3. **Metaä¿¡æ¯è‡ªåŠ¨è°ƒæ•´** âœ¨ï¼š`dataset.meta.episodes`ä¸­çš„`dataset_from_index`å’Œ`dataset_to_index`è‡ªåŠ¨è°ƒæ•´ï¼Œä¸å®é™…æ•°æ®ç´¢å¼•å®Œå…¨ä¸€è‡´
4. **å®Œå…¨å…¼å®¹**ï¼šä¿æŒä¸åŸå§‹ LeRobotDataset çš„æ¥å£å…¼å®¹
5. **é€æ˜è®¿é—®**ï¼šé€šè¿‡æ ‡å‡†ç´¢å¼•è®¿é—®ï¼Œå ä½ç¬¦è‡ªåŠ¨å¤„ç†
6. **é›¶æ–‡ä»¶ä¿®æ”¹**ï¼šçº¯å†…å­˜æ“ä½œï¼Œä¸ä¿®æ”¹ä»»ä½•ç£ç›˜æ–‡ä»¶

## ğŸ“‹ å ä½ç¬¦ç‰¹æ€§

æ¯ä¸ªå ä½ç¬¦å¸§åŒ…å«ï¼š

- `is_placeholder=True`ï¼šæ˜ç¡®æ ‡è®°ä¸ºå ä½ç¬¦
- `action`ï¼šå…¨ä¸º `-999.0`ï¼ˆå¯é…ç½®çš„ç‰¹æ®Šå€¼ï¼‰
- `observation`ï¼šå¤åˆ¶å‰ä¸€å¸§çš„è§‚æµ‹æ•°æ®
- `episode_index`ï¼šä¿æŒä¸æ‰€å± episode ç›¸åŒ
- `frame_index=-1`ï¼šæ— æ•ˆçš„å¸§ç´¢å¼•æ ‡è®°

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# ç¡®ä¿å·²å®‰è£… lerobot
pip install lerobot torch
```

### åŸºæœ¬ä½¿ç”¨

```python
from lerobot_dataset_with_placeholder import LeRobotDatasetWithPlaceholder

# åŠ è½½æ•°æ®é›†
dataset = LeRobotDatasetWithPlaceholder(
    repo_id='datasets_cut',
    root='/inspire/ssd/project/robot-decision/laijunxi-CZXS25230141/data_dealer_auto/datasets_cut',
    placeholder_action_value=-999.0  # å ä½ç¬¦çš„ action å€¼
)


dataset = LeRobotDatasetWithPlaceholder(
    repo_id='HuggingFaceVLA_cus/datasets_cut',
    root='/inspire/hdd/project/robot-decision/public/datasets/HuggingFaceVLA_cus/datasets_cut',
    placeholder_action_value=-999.0  # å ä½ç¬¦çš„ action å€¼
)

# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
print(f"æ€»å¸§æ•°: {len(dataset)} (åŒ…å«å ä½ç¬¦)")
print(f"åŸå§‹å¸§æ•°: {len(dataset.original_dataset)}")
print(f"å ä½ç¬¦æ•°: {dataset.num_placeholders}")

# è®¿é—®æ•°æ®
for i in range(len(dataset)):
    frame = dataset[i]
    
    if frame['is_placeholder'].item():
        print(f"å¸§ {i}: ğŸ”¶ å ä½ç¬¦ (episode {frame['episode_index'].item()})")
    else:
        print(f"å¸§ {i}: æ­£å¸¸å¸§ (episode {frame['episode_index'].item()})")

# ä½¿ç”¨metaä¿¡æ¯è®¿é—®episodeï¼ˆç´¢å¼•å·²è‡ªåŠ¨è°ƒæ•´ï¼ï¼‰
for ep_idx in range(len(dataset.meta.episodes)):
    ep_meta = dataset.meta.episodes[ep_idx]
    from_idx = ep_meta['dataset_from_index']
    to_idx = ep_meta['dataset_to_index']
    
    # ç›´æ¥ä½¿ç”¨metaä¸­çš„ç´¢å¼• - å·²è€ƒè™‘placeholderåç§»
    first_frame = dataset[from_idx]
    last_frame = dataset[to_idx]
    
    print(f"Episode {ep_idx}: èŒƒå›´ {from_idx}-{to_idx}, ä»»åŠ¡: {ep_meta['tasks']}")
```

### æŸ¥çœ‹æ•°æ®é›†ç»“æ„

```python
# æ‰“å°æ‰€æœ‰ episode çš„ç»“æ„
dataset.print_episode_structure()

# æŸ¥çœ‹ç‰¹å®š episode
dataset.print_episode_structure(chunk_idx=0)

# è·å– episode è¯¦ç»†ä¿¡æ¯
info = dataset.get_episode_info(chunk_idx=0)
print(f"Segments: {info['num_segments']}")
print(f"Placeholders: {info['num_placeholders']}")
```

### éªŒè¯å ä½ç¬¦

```python
# éªŒè¯å ä½ç¬¦æ˜¯å¦æ­£ç¡®æ’å…¥
dataset.verify_placeholders(num_samples=5)
```

### ä½¿ç”¨Metaä¿¡æ¯ï¼ˆé‡è¦ï¼ï¼‰âœ¨

**æ–°ç‰¹æ€§**ï¼š`dataset.meta.episodes`ä¸­çš„ç´¢å¼•å·²è‡ªåŠ¨è°ƒæ•´ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼

```python
# Metaä¿¡æ¯å·²è‡ªåŠ¨è°ƒæ•´ï¼Œè€ƒè™‘äº†placeholderçš„åç§»
ep_meta = dataset.meta.episodes[1]
from_idx = ep_meta['dataset_from_index']  # å·²è°ƒæ•´çš„ç´¢å¼•
to_idx = ep_meta['dataset_to_index']      # å·²è°ƒæ•´çš„ç´¢å¼•

# ç›´æ¥ä½¿ç”¨ï¼Œå®Œå…¨æ­£ç¡®ï¼
first_frame = dataset[from_idx]
last_frame = dataset[to_idx]

assert first_frame['episode_index'].item() == ep_meta['episode_index']
assert last_frame['episode_index'].item() == ep_meta['episode_index']

print(f"Episode {ep_meta['episode_index']}: ç´¢å¼•èŒƒå›´ {from_idx}-{to_idx}")
print(f"ä»»åŠ¡: {ep_meta['tasks']}")
```

å¦‚æœéœ€è¦è®¿é—®åŸå§‹çš„æœªè°ƒæ•´metaï¼š

```python
# è·å–åŸå§‹metaï¼ˆæœªè€ƒè™‘placeholderåç§»ï¼‰
original_ep = dataset.original_meta.episodes[1]
original_from = original_ep['dataset_from_index']
original_to = original_ep['dataset_to_index']

# æ¯”è¾ƒ
adjusted_ep = dataset.meta.episodes[1]
print(f"åŸå§‹èŒƒå›´: {original_from}-{original_to}")
print(f"è°ƒæ•´å: {adjusted_ep['dataset_from_index']}-{adjusted_ep['dataset_to_index']}")
print(f"åç§»: +{adjusted_ep['dataset_from_index'] - original_from}")
```

**é‡è¦è¯´æ˜**ï¼š
- âœ… `dataset.meta`ï¼šè¿”å›è°ƒæ•´åçš„metaï¼ˆæ¨èä½¿ç”¨ï¼‰
- âœ… `dataset.original_meta`ï¼šè¿”å›åŸå§‹metaï¼ˆå¦‚éœ€å¯¹æ¯”ï¼‰
- âœ… æ‰€æœ‰è°ƒæ•´éƒ½åœ¨å†…å­˜ä¸­å®Œæˆï¼Œ**ä¸ä¼šä¿®æ”¹ç£ç›˜æ–‡ä»¶**
- âœ… å®Œå…¨é€æ˜ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—åç§»é‡

## ğŸ“Š æ•°æ®ç»“æ„è¯´æ˜

### åŸå§‹æ•°æ®é›†ç»“æ„

å½“å‰ `cut_dataset` çš„ç»“æ„ï¼š

```
cut_dataset/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ episode_0/              # åŸå§‹ Episode 0
â”‚   â”‚   â”œâ”€â”€ segment_0.parquet   # Segment 0 (episode_index=0)
â”‚   â”‚   â”œâ”€â”€ segment_1.parquet   # Segment 1 (episode_index=1)
â”‚   â”‚   â”œâ”€â”€ segment_2.parquet   # Segment 2 (episode_index=2)
â”‚   â”‚   â””â”€â”€ segment_3.parquet   # Segment 3 (episode_index=3)
â”‚   â””â”€â”€ episode_1/              # åŸå§‹ Episode 1
â”‚       â”œâ”€â”€ segment_4.parquet   # Segment 0 (episode_index=4)
â”‚       â”œâ”€â”€ segment_5.parquet   # Segment 1 (episode_index=5)
â”‚       â”œâ”€â”€ segment_6.parquet   # Segment 2 (episode_index=6)
â”‚       â”œâ”€â”€ segment_7.parquet   # Segment 3 (episode_index=7)
â”‚       â”œâ”€â”€ segment_8.parquet   # Segment 4 (episode_index=8)
â”‚       â””â”€â”€ segment_9.parquet   # Segment 5 (episode_index=9)
```

### å ä½ç¬¦æ’å…¥ä½ç½®

**åŸå§‹ Episode 0** (4 ä¸ª segments â†’ 3 ä¸ªå ä½ç¬¦):
```
Segment 0 (frames 0-25)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 26]
Segment 1 (frames 26-51)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 53]
Segment 2 (frames 52-77)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 80]
Segment 3 (frames 78-99)
```

**åŸå§‹ Episode 1** (6 ä¸ª segments â†’ 5 ä¸ªå ä½ç¬¦):
```
Segment 0 (frames 100-125)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 129]
Segment 1 (frames 126-151)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 156]
Segment 2 (frames 152-177)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 183]
Segment 3 (frames 178-203)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 210]
Segment 4 (frames 204-229)
    â†“ [å ä½ç¬¦ @ æ–°ç´¢å¼• 237]
Segment 5 (frames 230-255)
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### åœ¨ motion_planning ä¸­ä½¿ç”¨

```python
from lerobot_dataset_with_placeholder import LeRobotDatasetWithPlaceholder
import torch

dataset = LeRobotDatasetWithPlaceholder(
    repo_id='cut_dataset',
    root='./cut_dataset',
    placeholder_action_value=-999.0
)

# è®­ç»ƒå¾ªç¯
for idx in range(len(dataset)):
    frame = dataset[idx]
    
    if frame['is_placeholder'].item():
        # å ä½ç¬¦å¸§ï¼šé‡ç½®æˆ–ç‰¹æ®Šå¤„ç†
        print(f"æ£€æµ‹åˆ°è·³è·ƒè¾¹ç•Œ @ ç´¢å¼• {idx}")
        # ä¾‹å¦‚ï¼šé‡ç½®è½¨è¿¹ç¼“å†²åŒºã€ä¿å­˜å½“å‰è½¨è¿¹ç‰‡æ®µç­‰
        continue
    
    # æ­£å¸¸å¸§ï¼šå¤„ç†è§‚æµ‹å’ŒåŠ¨ä½œ
    observation = {
        'image': frame['observation.images.image'],
        'state': frame['observation.state']
    }
    action = frame['action']
    
    # ä½ çš„è®­ç»ƒé€»è¾‘...
```

### è¿‡æ»¤å ä½ç¬¦

```python
# åªè·å–éå ä½ç¬¦å¸§
real_frames = [
    dataset[i] 
    for i in range(len(dataset)) 
    if not dataset[i]['is_placeholder'].item()
]

print(f"çœŸå®å¸§æ•°: {len(real_frames)}")
```

### æŒ‰ Episode è¿­ä»£

```python
# è¿­ä»£æ¯ä¸ªåŸå§‹ episode
for chunk_idx in sorted(dataset.episode_segments.keys()):
    info = dataset.get_episode_info(chunk_idx)
    
    print(f"\nå¤„ç†åŸå§‹ Episode {chunk_idx}")
    print(f"  åŒ…å« {info['num_segments']} ä¸ª segments")
    
    # è¿­ä»£è¯¥ episode çš„æ‰€æœ‰ segment
    for seg in info['segments']:
        print(f"  Segment {seg['episode_index']}: {seg['length']} å¸§")
        
        # è·å–è¯¥ segment çš„æ‰€æœ‰å¸§
        # æ³¨æ„ï¼šéœ€è¦å°†åŸå§‹ç´¢å¼•è½¬æ¢ä¸ºæ–°ç´¢å¼•ï¼ˆè€ƒè™‘å·²æ’å…¥çš„å ä½ç¬¦ï¼‰
```

## ğŸ“ˆ æ€§èƒ½è¯´æ˜

- **å†…å­˜å¼€é”€**ï¼šå ä½ç¬¦æŒ‰éœ€ç”Ÿæˆï¼Œä¸å ç”¨é¢å¤–å­˜å‚¨ç©ºé—´
- **è®¿é—®é€Ÿåº¦**ï¼šå•æ¬¡è®¿é—® O(1)ï¼Œä¸åŸå§‹æ•°æ®é›†ç›¸åŒ
- **åˆå§‹åŒ–æ—¶é—´**ï¼šé¢å¤–åˆ†æ episode ç»“æ„ï¼Œçº¦å¢åŠ  < 1 ç§’

## ğŸ” è°ƒè¯•å’ŒéªŒè¯

### è¿è¡Œæ¼”ç¤ºè„šæœ¬

```bash
cd /home/dongyingyibadao/data_dealer_auto
conda run -p /home/dongyingyibadao/miniconda3/envs/libero python lerobot_dataset_with_placeholder.py
```

### æ£€æŸ¥ç‰¹å®šå¸§

```python
# æŸ¥çœ‹ Segment è¾¹ç•Œå¤„çš„å¸§
for i in range(24, 29):  # Segment 0-1 è¾¹ç•Œé™„è¿‘
    frame = dataset[i]
    print(f"ç´¢å¼• {i}:")
    print(f"  episode_index: {frame['episode_index'].item()}")
    print(f"  is_placeholder: {frame['is_placeholder'].item()}")
    print(f"  action: {frame['action'][:3].tolist()}")
```

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆéœ€è¦å ä½ç¬¦ï¼Ÿ

**A**: å½“ä¸€ä¸ªå®Œæ•´çš„æœºå™¨äººä»»åŠ¡è¢«åˆ‡åˆ†æˆå¤šä¸ªç‰‡æ®µï¼ˆsegmentsï¼‰æ—¶ï¼Œç›¸é‚»ç‰‡æ®µä¹‹é—´å¯èƒ½å­˜åœ¨æ—¶é—´æˆ–åŠ¨ä½œçš„è·³è·ƒã€‚å ä½ç¬¦å¸®åŠ© motion_planning ç³»ç»Ÿè¯†åˆ«è¿™äº›è·³è·ƒè¾¹ç•Œï¼Œé¿å…æ¨¡å‹é”™è¯¯åœ°å°†éè¿ç»­åŠ¨ä½œå½“ä½œè¿ç»­è½¨è¿¹å­¦ä¹ ã€‚

### Q2: å ä½ç¬¦ä¼šå½±å“è®­ç»ƒå—ï¼Ÿ

**A**: ä¸ä¼šã€‚å ä½ç¬¦æœ‰æ˜ç¡®çš„ `is_placeholder=True` æ ‡è®°å’Œç‰¹æ®Šçš„ action å€¼ï¼ˆ-999ï¼‰ï¼Œä½ å¯ä»¥åœ¨è®­ç»ƒå¾ªç¯ä¸­è·³è¿‡å®ƒä»¬ï¼Œæˆ–ç”¨äºè§¦å‘ç‰¹æ®Šé€»è¾‘ï¼ˆå¦‚è½¨è¿¹ç‰‡æ®µçš„åˆ†å‰²ï¼‰ã€‚

### Q3: å¦‚ä½•è‡ªå®šä¹‰å ä½ç¬¦çš„ action å€¼ï¼Ÿ

**A**: åœ¨åˆ›å»ºæ•°æ®é›†æ—¶æŒ‡å®š `placeholder_action_value` å‚æ•°ï¼š

```python
dataset = LeRobotDatasetWithPlaceholder(
    repo_id='cut_dataset',
    root='./cut_dataset',
    placeholder_action_value=-1000.0  # è‡ªå®šä¹‰å€¼
)
```

### Q4: ä¸åŒ episode ä¹‹é—´ä¼šæ’å…¥å ä½ç¬¦å—ï¼Ÿ

**A**: ä¸ä¼šã€‚å ä½ç¬¦åªåœ¨**åŒä¸€åŸå§‹ episode** çš„ä¸åŒ segments ä¹‹é—´æ’å…¥ã€‚ä¸åŒçš„åŸå§‹ episode ä¹‹é—´ä¿æŒç‹¬ç«‹ï¼Œä¸æ’å…¥å ä½ç¬¦ã€‚

### Q5: å¦‚ä½•è·å–åŸå§‹æ•°æ®é›†ï¼Ÿ

**A**: é€šè¿‡ `dataset.original_dataset` è®¿é—®ï¼š

```python
original_frame = dataset.original_dataset[100]  # åŸå§‹ç´¢å¼•
```

### Q6: Metaä¿¡æ¯çš„ç´¢å¼•ä¼šè‡ªåŠ¨è°ƒæ•´å—ï¼Ÿâœ¨

**A**: æ˜¯çš„ï¼ä»ç‰ˆæœ¬1.1å¼€å§‹ï¼Œ`dataset.meta.episodes`ä¸­çš„`dataset_from_index`å’Œ`dataset_to_index`ä¼šè‡ªåŠ¨è°ƒæ•´ä»¥è€ƒè™‘placeholderçš„åç§»ã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›ç´¢å¼•ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—ï¼š

```python
ep_meta = dataset.meta.episodes[1]
from_idx = ep_meta['dataset_from_index']  # å·²è‡ªåŠ¨è°ƒæ•´

# ç›´æ¥ä½¿ç”¨ï¼Œå®Œå…¨æ­£ç¡®
frame = dataset[from_idx]
```

å¦‚æœéœ€è¦åŸå§‹çš„æœªè°ƒæ•´ç´¢å¼•ï¼Œä½¿ç”¨`dataset.original_meta`ã€‚

### Q7: ä¼šä¿®æ”¹åŸå§‹çš„metaæ–‡ä»¶å—ï¼Ÿ

**A**: **ä¸ä¼šï¼**æ‰€æœ‰metaè°ƒæ•´éƒ½æ˜¯çº¯å†…å­˜æ“ä½œï¼š
- âŒ ä¸ä¿®æ”¹ `meta/info.json`
- âŒ ä¸ä¿®æ”¹ `meta/stats.json`
- âŒ ä¸ä¿®æ”¹ `meta/episodes/` ä¸‹çš„ä»»ä½•æ–‡ä»¶
- âœ… åªåœ¨å†…å­˜ä¸­åˆ›å»ºåŒ…è£…å™¨ï¼ŒåŠ¨æ€è¿”å›è°ƒæ•´åçš„å€¼
- âœ… ç¨‹åºç»“æŸåï¼Œæ‰€æœ‰è°ƒæ•´æ¶ˆå¤±ï¼ˆå› ä¸ºåªåœ¨å†…å­˜ä¸­ï¼‰

åŸå§‹æ•°æ®é›†æ–‡ä»¶å®Œå…¨å®‰å…¨ï¼Œä¸ä¼šè¢«ä¿®æ”¹ã€‚æ¯æ¬¡é‡æ–°åŠ è½½æ—¶ï¼Œéƒ½ä¼šä»åŸå§‹æ–‡ä»¶è¯»å–ã€‚

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### chunk_index vs episode_index

- **chunk_index**: åŸå§‹ episode çš„ç´¢å¼•ï¼ˆä¾‹å¦‚ episode_0, episode_1ï¼‰
- **episode_index**: åˆ‡åˆ†åçš„ segment ç´¢å¼•ï¼ˆ0, 1, 2, ...ï¼‰

ä¸€ä¸ª chunk_index å¯ä»¥å¯¹åº”å¤šä¸ª episode_indexã€‚ä¾‹å¦‚ï¼š
- chunk_index=0 â†’ episode_index=[0, 1, 2, 3]
- chunk_index=1 â†’ episode_index=[4, 5, 6, 7, 8, 9]

### ç´¢å¼•æ˜ å°„

```python
# æ–°ç´¢å¼• -> (åŸå§‹ç´¢å¼•, is_placeholder, placeholder_info)
new_to_original_idx = [
    (0, False),       # æ–°ç´¢å¼• 0 = åŸå§‹ç´¢å¼• 0
    (1, False),       # æ–°ç´¢å¼• 1 = åŸå§‹ç´¢å¼• 1
    ...
    (25, False),      # æ–°ç´¢å¼• 25 = åŸå§‹ç´¢å¼• 25
    (-1, True, {...}),  # æ–°ç´¢å¼• 26 = å ä½ç¬¦
    (26, False),      # æ–°ç´¢å¼• 27 = åŸå§‹ç´¢å¼• 26
    ...
]
```

### Metaä¿¡æ¯åŠ¨æ€è°ƒæ•´æœºåˆ¶âœ¨

ä¸ºäº†ä¿æŒmetaä¿¡æ¯ä¸å®é™…æ•°æ®ç´¢å¼•ä¸€è‡´ï¼Œä½¿ç”¨äº†**åŒ…è£…å™¨æ¨¡å¼**ï¼š

```python
class AdjustedEpisodesWrapper:
    """åŠ¨æ€è°ƒæ•´episodeçš„dataset_from_indexå’Œdataset_to_index"""
    
    def __getitem__(self, idx):
        original_ep = self._original_episodes[idx]
        adjusted_ep = dict(original_ep)  # åˆ›å»ºå‰¯æœ¬ï¼Œä¸ä¿®æ”¹åŸå§‹æ•°æ®
        
        # åº”ç”¨ç´¢å¼•åç§»
        adjusted_ep['dataset_from_index'] = self._adjusted_ranges[idx]['dataset_from_index']
        adjusted_ep['dataset_to_index'] = self._adjusted_ranges[idx]['dataset_to_index']
        
        return adjusted_ep

class AdjustedMetadataWrapper:
    """åŒ…è£…åŸå§‹metaï¼Œè¿”å›è°ƒæ•´åçš„episodes"""
    
    @property
    def episodes(self):
        return self._adjusted_episodes  # è¿”å›åŒ…è£…å™¨
```

**å·¥ä½œæµç¨‹**ï¼š
1. åŠ è½½æ•°æ®é›†æ—¶ï¼Œæ„å»ºåŸå§‹ç´¢å¼•åˆ°æ–°ç´¢å¼•çš„æ˜ å°„è¡¨
2. ä¸ºæ¯ä¸ªepisodeè®¡ç®—è°ƒæ•´åçš„`dataset_from_index`å’Œ`dataset_to_index`
3. åˆ›å»ºåŒ…è£…å™¨å¯¹è±¡ï¼Œåœ¨è®¿é—®æ—¶åŠ¨æ€è¿”å›è°ƒæ•´åçš„å€¼
4. åŸå§‹metaæ–‡ä»¶ä¿æŒä¸å˜ï¼ˆçº¯å†…å­˜æ“ä½œï¼‰

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨é€æ˜ï¼Œä½¿ç”¨æ–¹å¼ä¸åŸå§‹LeRobotDatasetç›¸åŒ
- âœ… è‡ªåŠ¨è°ƒæ•´ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—åç§»
- âœ… é›¶æ–‡ä»¶ä¿®æ”¹ï¼ŒåŸå§‹æ•°æ®å®‰å…¨
- âœ… æƒ°æ€§è®¡ç®—ï¼Œä¸æµªè´¹å†…å­˜

## ğŸ¤ ä¸å…¶ä»–ç³»ç»Ÿé›†æˆ

### ä¸ PyTorch DataLoader ä½¿ç”¨

```python
from torch.utils.data import DataLoader

dataset = LeRobotDatasetWithPlaceholder(
    repo_id='cut_dataset',
    root='./cut_dataset'
)

# è‡ªå®šä¹‰ collate_fn è¿‡æ»¤å ä½ç¬¦
def collate_fn(batch):
    # è¿‡æ»¤æ‰å ä½ç¬¦
    batch = [item for item in batch if not item['is_placeholder'].item()]
    if not batch:
        return None
    # æ ‡å‡†çš„ batch å¤„ç†...
    return torch.utils.data.default_collate(batch)

loader = DataLoader(
    dataset,
    batch_size=32,
    collate_fn=collate_fn,
    shuffle=True
)
```

### ä¸ LeRobot è®­ç»ƒç®¡é“é›†æˆ

```python
# æ›¿æ¢åŸå§‹æ•°æ®é›†
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot_dataset_with_placeholder import LeRobotDatasetWithPlaceholder

# åŸæ¥çš„ä»£ç 
# dataset = LeRobotDataset('cut_dataset', root='./cut_dataset')

# æ–°ä»£ç 
dataset = LeRobotDatasetWithPlaceholder(
    repo_id='cut_dataset',
    root='./cut_dataset'
)

# å…¶ä»–ä»£ç ä¿æŒä¸å˜
# dataset[i] è¿”å›çš„æ•°æ®æ ¼å¼å®Œå…¨ç›¸åŒï¼Œåªæ˜¯å¤šäº† is_placeholder å­—æ®µ
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LeRobot å®˜æ–¹æ–‡æ¡£](https://github.com/huggingface/lerobot)
- [Data Dealer Auto ä½¿ç”¨æŒ‡å—](./README.md)
- [æ•°æ®é›†æ ¼å¼ä¿®å¤æ€»ç»“](./FINAL_FIX_SUMMARY.md)

## ğŸ› é—®é¢˜åé¦ˆ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š

1. âœ… æ•°æ®é›†è·¯å¾„æ­£ç¡®
2. âœ… `meta/episodes/chunk-000/file-000.parquet` å­˜åœ¨
3. âœ… æ•°æ®é›†åŒ…å« `data/chunk_index` å­—æ®µ
4. âœ… LeRobot ç‰ˆæœ¬ >= 3.0

## ğŸ“Š ç¤ºä¾‹è¾“å‡º

```
ğŸ”§ åˆå§‹åŒ–å¸¦å ä½ç¬¦çš„ LeRobot Dataset...
   repo_id: cut_dataset
   root: ./cut_dataset
ğŸ” åˆ†æ episode ç»“æ„...
   åˆ†æå®Œæˆ:
   - åŸå§‹ Episodes (chunk_index): 2
   - åˆ‡åˆ†åçš„ Segments: 10
   - å¤š Segment Episodes: 2
   - éœ€æ’å…¥å ä½ç¬¦: 8 ä¸ª
   åŸå§‹ Episode 0 (chunk_index): 4 segments
      Segment 0 (episode_index=0): frames 0-25 (length=26)
      Segment 1 (episode_index=1): frames 26-51 (length=26)
      Segment 2 (episode_index=2): frames 52-77 (length=26)
      Segment 3 (episode_index=3): frames 78-99 (length=22)
   åŸå§‹ Episode 1 (chunk_index): 6 segments
      Segment 0 (episode_index=4): frames 100-125 (length=26)
      ...
âœ… æ•°æ®é›†åŠ è½½å®Œæˆ
   åŸå§‹å¸§æ•°: 256
   æ–°å¢å ä½ç¬¦: 8
   æ€»å¸§æ•°: 264
   Episodeæ•°: 2
```

---

## ğŸ“š æ›´æ–°æ—¥å¿—

### v1.1.0 (2024-12-13) âœ¨
- âœ… æ–°å¢ï¼šMetaä¿¡æ¯è‡ªåŠ¨è°ƒæ•´åŠŸèƒ½
- âœ… æ–°å¢ï¼š`dataset.meta.episodes`ä¸­çš„ç´¢å¼•è‡ªåŠ¨è€ƒè™‘placeholderåç§»
- âœ… æ–°å¢ï¼š`dataset.original_meta`å±æ€§è®¿é—®åŸå§‹meta
- âœ… æ”¹è¿›ï¼šå®Œå…¨é€æ˜çš„ä½¿ç”¨ä½“éªŒï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—åç§»
- âœ… ä¿è¯ï¼šçº¯å†…å­˜æ“ä½œï¼Œä¸ä¿®æ”¹ä»»ä½•ç£ç›˜æ–‡ä»¶

### v1.0.0 (2024-12-09)
- âœ… åˆå§‹ç‰ˆæœ¬ï¼šè‡ªåŠ¨æ’å…¥placeholderåŠŸèƒ½
- âœ… Episodeç»“æ„åˆ†æå’Œå¯è§†åŒ–
- âœ… PlaceholderéªŒè¯å·¥å…·

---

**ç‰ˆæœ¬**: 1.1.0  
**ä½œè€…**: GitHub Copilot AI Assistant  
**æœ€åæ›´æ–°**: 2024-12-13
