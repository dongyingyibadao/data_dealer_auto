# LeRobot æ•°æ®é›†æ ¼å¼å®Œæ•´ä¿®å¤æ€»ç»“

æœ¬æ–‡æ¡£è®°å½•äº† `data_dealer_auto` ç”Ÿæˆçš„æ•°æ®é›†ä¸ºå…¼å®¹ LeRobot v3.0 æ ¼å¼æ‰€åšçš„æ‰€æœ‰ä¿®å¤ã€‚

---

## ğŸ“‹ ç›®å½•

1. [é—®é¢˜æ¦‚è¿°](#é—®é¢˜æ¦‚è¿°)
2. [ä¿®å¤1ï¼šæ·»åŠ å¿…éœ€çš„å…ƒæ•°æ®å­—æ®µ](#ä¿®å¤1æ·»åŠ å¿…éœ€çš„å…ƒæ•°æ®å­—æ®µ)
3. [ä¿®å¤2ï¼šæ·»åŠ æ•°æ®æ–‡ä»¶å®šä½å­—æ®µ](#ä¿®å¤2æ·»åŠ æ•°æ®æ–‡ä»¶å®šä½å­—æ®µ)
4. [ä¿®å¤3ï¼šä¿®å¤episode_indexè¦†ç›–é—®é¢˜](#ä¿®å¤3ä¿®å¤episode_indexè¦†ç›–é—®é¢˜)
5. [ä¿®å¤4ï¼šå®ç°æ­£ç¡®çš„task_indexæ˜ å°„](#ä¿®å¤4å®ç°æ­£ç¡®çš„task_indexæ˜ å°„)
6. [ä¿®å¤5ï¼šä¿®å¤tasks.parquetæ ¼å¼](#ä¿®å¤5ä¿®å¤tasksparquetæ ¼å¼)
7. [éªŒè¯ç»“æœ](#éªŒè¯ç»“æœ)
8. [LeRobotæ ¼å¼è¦æ±‚æ€»ç»“](#lerobotæ ¼å¼è¦æ±‚æ€»ç»“)

---

## é—®é¢˜æ¦‚è¿°

ç”Ÿæˆçš„ `cut_dataset` æ— æ³•è¢« `LeRobotDataset` åŠ è½½ï¼Œå‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š

1. âŒ ç¼ºå°‘ `info.json` çš„ `features` å­—æ®µ
2. âŒ Parquet æ–‡ä»¶ç¼ºå°‘å…ƒæ•°æ®å­—æ®µï¼š`episode_index`, `frame_index`, `index`, `task_index`
3. âŒ Episode å…ƒæ•°æ®ç¼ºå°‘ `data/chunk_index` å’Œ `data/file_index`
4. âŒ æ‰€æœ‰å¸§çš„ `episode_index` éƒ½æ˜¯ 0ï¼ˆåº”è¯¥æ˜¯ 0, 1, 2, ...ï¼‰
5. âŒ æ‰€æœ‰å¸§çš„ `task_index` éƒ½æ˜¯ 0ï¼ˆåº”è¯¥æ ¹æ®ä»»åŠ¡åˆ†é…ï¼‰
6. âŒ `frame['task']` è¿”å›æ•°å­—è€Œä¸æ˜¯ä»»åŠ¡æè¿°å­—ç¬¦ä¸²

---

## ä¿®å¤1ï¼šæ·»åŠ å¿…éœ€çš„å…ƒæ•°æ®å­—æ®µ

### é—®é¢˜
Parquet æ•°æ®æ–‡ä»¶ç¼ºå°‘ 4 ä¸ªå…ƒæ•°æ®å­—æ®µï¼Œå¯¼è‡´ LeRobot æ— æ³•æ­£ç¡®ç´¢å¼•å’Œæ£€ç´¢æ•°æ®ã€‚

### è§£å†³æ–¹æ¡ˆ

**æ–‡ä»¶**: `dataset_cutter.py` ç¬¬307-320è¡Œ

æ·»åŠ å…ƒæ•°æ®å­—æ®µåˆ°æ¯ä¸ªå¸§è®°å½•ï¼š

```python
record = {
    'observation.images.image': frame['observation.images.image'],
    'observation.images.image2': frame['observation.images.image2'],
    'observation.state': frame['observation.state'],
    'action': frame['action'],
    'timestamp': frame.get('timestamp', torch.tensor(0.0)),
    # æ–°å¢ï¼šå¿…éœ€çš„å…ƒæ•°æ®å­—æ®µ
    'episode_index': torch.tensor(new_episode_idx),  # Episodeç´¢å¼•
    'frame_index': torch.tensor(local_idx),          # Episodeå†…å¸§ç´¢å¼•
    'index': torch.tensor(global_frame_idx),         # å…¨å±€å¸§ç´¢å¼•
    'task_index': torch.tensor(current_task_index),  # ä»»åŠ¡ç´¢å¼•
}
```

åŒæ—¶æ›´æ–° `info.json` çš„ `features` å­—æ®µå®šä¹‰ï¼ˆç¬¬447-519è¡Œï¼‰ï¼š

```python
'features': {
    # ... è§‚æµ‹å’ŒåŠ¨ä½œå­—æ®µ ...
    'episode_index': {
        'dtype': 'int64',
        'shape': [1],
        'names': None,
        'fps': 10.0
    },
    'frame_index': {
        'dtype': 'int64',
        'shape': [1],
        'names': None,
        'fps': 10.0
    },
    'index': {
        'dtype': 'int64',
        'shape': [1],
        'names': None,
        'fps': 10.0
    },
    'task_index': {
        'dtype': 'int64',
        'shape': [1],
        'names': None,
        'fps': 10.0
    }
}
```

---

## ä¿®å¤2ï¼šæ·»åŠ æ•°æ®æ–‡ä»¶å®šä½å­—æ®µ

### é—®é¢˜
Episode å…ƒæ•°æ®ç¼ºå°‘ `data/chunk_index` å’Œ `data/file_index`ï¼Œå¯¼è‡´ LeRobot æ— æ³•é€šè¿‡ `get_data_file_path()` å®šä½æ¯ä¸ª episode çš„æ•°æ®æ–‡ä»¶ã€‚

### LeRobot çš„æ–‡ä»¶å®šä½æœºåˆ¶

```python
# lerobot_dataset.py ç¬¬197-200è¡Œ
ep = self.episodes[ep_index]
chunk_idx = ep["data/chunk_index"]
file_idx = ep["data/file_index"]
fpath = self.data_path.format(chunk_index=chunk_idx, file_index=file_idx)
```

### è§£å†³æ–¹æ¡ˆ

**æ–‡ä»¶**: `dataset_cutter.py` ç¬¬288-305è¡Œ

åœ¨ episode å…ƒæ•°æ®ä¸­æ·»åŠ æ–‡ä»¶å®šä½å­—æ®µï¼š

```python
episode_meta = {
    'episode_index': new_episode_idx,
    'tasks': np.array([metadata['new_task']]),
    # æ–°å¢ï¼šLeRobot å¿…éœ€çš„æ•°æ®æ–‡ä»¶å®šä½å­—æ®µ
    'data/chunk_index': to_int(metadata['episode_index']),  # ä½¿ç”¨åŸå§‹episodeä½œä¸ºchunk
    'data/file_index': new_episode_idx,                     # ä½¿ç”¨æ–°episode indexä½œä¸ºfile index
    'dataset_from_index': global_frame_idx,
    'dataset_to_index': global_frame_idx + num_frames - 1,
    'length': num_frames,
    # ... å…¶ä»–å­—æ®µ ...
}
```

åŒæ—¶æ›´æ–° `info.json` çš„ `data_path` æ¨¡æ¿ï¼ˆç¬¬468è¡Œï¼‰ï¼š

```python
'data_path': 'data/episode_{chunk_index}/segment_{file_index}.parquet',
```

**æ–‡ä»¶ç»“æ„ç¤ºä¾‹**ï¼š
```
data/
â”œâ”€â”€ episode_0/
â”‚   â”œâ”€â”€ segment_0.parquet   # chunk_index=0, file_index=0
â”‚   â”œâ”€â”€ segment_1.parquet   # chunk_index=0, file_index=1
â”‚   â””â”€â”€ segment_2.parquet   # chunk_index=0, file_index=2
```

---

## ä¿®å¤3ï¼šä¿®å¤episode_indexè¦†ç›–é—®é¢˜

### é—®é¢˜
åœ¨ä¿å­˜å¸§æ•°æ®æ—¶ï¼Œä½¿ç”¨äº† `frame.get('episode_index', default)` è·å–åŸå§‹æ•°æ®çš„ episode_indexï¼Œå¯¼è‡´æ‰€æœ‰åˆ‡åˆ†åçš„ç‰‡æ®µéƒ½ä¿ç•™äº†åŸå§‹æ•°æ®é›†çš„ episode_indexï¼ˆéƒ½æ˜¯0ï¼‰ï¼Œè€Œä¸æ˜¯æ–°åˆ†é…çš„ 0, 1, 2, ...

### æ ¹æœ¬åŸå› 

```python
# é”™è¯¯ä»£ç ï¼ˆä¿®å¤å‰ï¼‰
'episode_index': frame.get('episode_index', torch.tensor(new_episode_idx)),
```

å¦‚æœåŸå§‹ frame å·²æœ‰ `episode_index` å­—æ®µï¼Œ`.get()` ä¼šè¿”å›åŸå§‹å€¼è€Œä¸æ˜¯é»˜è®¤å€¼ã€‚

### è§£å†³æ–¹æ¡ˆ

**æ–‡ä»¶**: `dataset_cutter.py` ç¬¬310-324è¡Œ

**å¼ºåˆ¶è¦†ç›–**åŸå§‹å€¼ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ `.get()` çš„é»˜è®¤å€¼ï¼š

```python
# å‡†å¤‡å¸§æ•°æ®
frame_records = []
for local_idx, frame in enumerate(frames):
    record = {
        'observation.images.image': frame['observation.images.image'],
        'observation.images.image2': frame['observation.images.image2'],
        'observation.state': frame['observation.state'],
        'action': frame['action'],
        'timestamp': frame.get('timestamp', torch.tensor(0.0)),
        # å¼ºåˆ¶ä½¿ç”¨æ–°çš„ç´¢å¼•å€¼ï¼ˆä¸ä½¿ç”¨.getï¼‰
        'episode_index': torch.tensor(new_episode_idx),  # âœ… ç›´æ¥èµ‹å€¼
        'frame_index': torch.tensor(local_idx),
        'index': torch.tensor(global_frame_idx - num_frames + local_idx),
        'task_index': torch.tensor(current_task_index),
    }
    frame_records.append(record)
```

---

## ä¿®å¤4ï¼šå®ç°æ­£ç¡®çš„task_indexæ˜ å°„

### é—®é¢˜
æ‰€æœ‰å¸§çš„ `task_index` éƒ½è¢«ç¡¬ç¼–ç ä¸º 0ï¼Œæ²¡æœ‰æ ¹æ®å®é™…ä»»åŠ¡æè¿°åˆ†é…ä¸åŒçš„ç´¢å¼•ã€‚

```python
# é”™è¯¯ä»£ç ï¼ˆä¿®å¤å‰ï¼‰
'task_index': torch.tensor(0),  # âŒ æ‰€æœ‰å¸§éƒ½æ˜¯0
```

### LeRobot çš„ task_index æœºåˆ¶

åœ¨åŸå§‹æ•°æ®é›†ä¸­ï¼Œ`task_index` ç”¨äºåŒºåˆ†ä¸åŒçš„ä»»åŠ¡ç±»å‹ï¼š
- Episode 0: task_index=0, task="put the white mug on the left plate..."
- Episode 1: task_index=1, task="put the white mug on the plate..."
- Episode 2: task_index=2, task="put the yellow and white mug in the microwave..."
- Episode 3: task_index=2, task="put the yellow and white mug in the microwave..."ï¼ˆç›¸åŒä»»åŠ¡ï¼‰

**ç›¸åŒä»»åŠ¡æè¿° â†’ ç›¸åŒ task_index**

### è§£å†³æ–¹æ¡ˆ

**æ–‡ä»¶**: `dataset_cutter.py`

#### æ­¥éª¤1ï¼šæ„å»ºä»»åŠ¡æ˜ å°„è¡¨ï¼ˆç¬¬262-272è¡Œï¼‰

```python
# é¦–å…ˆæ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ä»»åŠ¡æè¿°ï¼Œæ„å»ºä»»åŠ¡ç´¢å¼•æ˜ å°„
task_to_index = {}
for cut_range_id, episode_data in sorted(episodes_data.items()):
    task_desc = episode_data['metadata']['new_task']
    if task_desc not in task_to_index:
        task_to_index[task_desc] = len(task_to_index)

print(f"\n  ä»»åŠ¡æ˜ å°„è¡¨:")
for task, idx in sorted(task_to_index.items(), key=lambda x: x[1]):
    print(f"    {idx}: {task}")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ä»»åŠ¡æ˜ å°„è¡¨:
  0: pick up the white
  1: put the white on the left
  2: put the white on the plate
  3: pick up the yellow
```

#### æ­¥éª¤2ï¼šä¸ºæ¯ä¸ªå¸§åˆ†é…æ­£ç¡®çš„task_indexï¼ˆç¬¬313-327è¡Œï¼‰

```python
# è·å–å½“å‰episodeçš„task_index
current_task = metadata['new_task']
current_task_index = task_to_index[current_task]

# å‡†å¤‡å¸§æ•°æ®
for local_idx, frame in enumerate(frames):
    record = {
        # ... å…¶ä»–å­—æ®µ ...
        'task_index': torch.tensor(current_task_index),  # âœ… ä½¿ç”¨æ­£ç¡®çš„ä»»åŠ¡ç´¢å¼•
    }
```

---

## ä¿®å¤5ï¼šä¿®å¤tasks.parquetæ ¼å¼

### é—®é¢˜
`frame['task']` è¿”å›æ•°å­—ï¼ˆ0, 1, 2ï¼‰è€Œä¸æ˜¯ä»»åŠ¡æè¿°å­—ç¬¦ä¸²ã€‚

### æ ¹æœ¬åŸå› 

LeRobot çš„ `__getitem__` æ–¹æ³•ï¼ˆlerobot_dataset.py:1025-1026ï¼‰ï¼š

```python
task_idx = item["task_index"].item()
item["task"] = self.meta.tasks.iloc[task_idx].name  # ä½¿ç”¨ .name è·å–è¡Œå
```

**å…³é”®**ï¼š`.iloc[i].name` è¿”å›çš„æ˜¯ DataFrame çš„ **index**ï¼ˆè¡Œåï¼‰ï¼Œè€Œä¸æ˜¯åˆ—å€¼ã€‚

### é”™è¯¯çš„æ ¼å¼ï¼ˆä¿®å¤å‰ï¼‰

```python
# é”™è¯¯ï¼šä»»åŠ¡æè¿°ä½œä¸ºåˆ—
tasks_df = pd.DataFrame([
    {'task_index': 0, 'task': 'pick up the white'},
    {'task_index': 1, 'task': 'put the white on the left'},
])
tasks_df.to_parquet(file, index=False)
```

ç”Ÿæˆçš„ç»“æ„ï¼š
```
   task_index                  task
0           0     pick up the white
1           1  put the white on the left
```

`tasks.iloc[0].name` è¿”å› `0`ï¼ˆæ•°å­—indexï¼‰âŒ

### æ­£ç¡®çš„æ ¼å¼ï¼ˆä¿®å¤åï¼‰

**æ–‡ä»¶**: `dataset_cutter.py` ç¬¬368-374è¡Œ

```python
# æ­£ç¡®ï¼šä»»åŠ¡æè¿°ä½œä¸º DataFrame çš„ indexï¼ˆè¡Œåï¼‰
tasks_data = []
for task, task_idx in sorted(task_to_index.items(), key=lambda x: x[1]):
    tasks_data.append({'task': task, 'task_index': task_idx})

tasks_df = pd.DataFrame(tasks_data)
# å°†ä»»åŠ¡æè¿°è®¾ä¸ºindexï¼ˆè¿™æ˜¯LeRobotæœŸæœ›çš„æ ¼å¼ï¼‰
tasks_df = tasks_df.set_index('task')
tasks_file = self.output_dir / 'meta' / 'tasks.parquet'
tasks_df.to_parquet(tasks_file, index=True)  # âœ… ç¡®ä¿ä¿å­˜index
```

ç”Ÿæˆçš„ç»“æ„ï¼š
```
                            task_index
task                                  
pick up the white                    0
put the white on the left            1
put the white on the plate           2
pick up the yellow                   3
```

`tasks.iloc[0].name` è¿”å› `"pick up the white"`ï¼ˆå­—ç¬¦ä¸²ï¼‰âœ…

---

## éªŒè¯ç»“æœ

### 1. æ•°æ®é›†åŠ è½½æˆåŠŸ

```python
from lerobot.datasets.lerobot_dataset import LeRobotDataset

ds = LeRobotDataset('cut_dataset', root='/path/to/cut_dataset')
# âœ… æˆåŠŸåŠ è½½
# æ€»å¸§æ•°: 282
# Episodeæ•°: 11
```

### 2. Episodes æ­£ç¡®åˆ†ç¦»

```python
unique_episodes = set(ds.hf_dataset.unique('episode_index'))
# âœ… {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}  # 11ä¸ªä¸åŒçš„episodes
```

### 3. Task_index æ­£ç¡®åˆ†é…

```python
for ep_idx in range(ds.num_episodes):
    frame = ds[ds.meta.episodes[ep_idx]['dataset_from_index']]
    print(f"Episode {ep_idx}: task_index={frame['task_index'].item()}")

# âœ… è¾“å‡ºï¼š
# Episode 0: task_index=0
# Episode 1: task_index=1
# Episode 2: task_index=0  # ç›¸åŒä»»åŠ¡ï¼Œç›¸åŒç´¢å¼•
# Episode 3: task_index=1
# Episode 5: task_index=2
# Episode 7: task_index=3
```

### 4. Task å­—æ®µè¿”å›å­—ç¬¦ä¸²

```python
frame = ds[0]
print(frame['task'])
# âœ… "pick up the white"ï¼ˆå­—ç¬¦ä¸²ï¼‰
# âŒ ä¸æ˜¯ "0"ï¼ˆæ•°å­—ï¼‰
```

### 5. æ‰€æœ‰å­—æ®µå®Œæ•´

```python
frame = ds[300]
print(frame.keys())
# âœ… ['observation.images.image', 'observation.images.image2', 
#     'observation.state', 'action', 'timestamp',
#     'episode_index', 'frame_index', 'index', 'task_index', 'task']
```

---

## LeRobotæ ¼å¼è¦æ±‚æ€»ç»“

### å¿…éœ€çš„ç›®å½•ç»“æ„

```
dataset_root/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ <subdirs>/
â”‚       â””â”€â”€ *.parquet          # å¸§æ•°æ®
â”œâ”€â”€ meta/
â”‚   â”œâ”€â”€ info.json              # æ•°æ®é›†å…ƒä¿¡æ¯ï¼ˆå¿…éœ€ï¼‰
â”‚   â”œâ”€â”€ stats.json             # ç»Ÿè®¡ä¿¡æ¯
â”‚   â”œâ”€â”€ tasks.parquet          # ä»»åŠ¡åˆ—è¡¨ï¼ˆindex=ä»»åŠ¡æè¿°ï¼‰
â”‚   â””â”€â”€ episodes/              # Episodeså…ƒæ•°æ®
â”‚       â””â”€â”€ chunk-000/
â”‚           â””â”€â”€ file-000.parquet
```

### info.json å¿…éœ€å­—æ®µ

```json
{
  "codebase_version": "v3.0",
  "total_episodes": 11,
  "total_frames": 282,
  "data_path": "data/episode_{chunk_index}/segment_{file_index}.parquet",
  "features": {
    "observation.images.image": { "dtype": "image", ... },
    "observation.state": { "dtype": "float32", ... },
    "action": { "dtype": "float32", ... },
    "timestamp": { "dtype": "float32", ... },
    "episode_index": { "dtype": "int64", ... },  // å¿…éœ€
    "frame_index": { "dtype": "int64", ... },    // å¿…éœ€
    "index": { "dtype": "int64", ... },          // å¿…éœ€
    "task_index": { "dtype": "int64", ... }      // å¿…éœ€
  }
}
```

### episodes å…ƒæ•°æ®å¿…éœ€å­—æ®µ

```python
{
    'episode_index': 0,
    'data/chunk_index': 0,      # ç”¨äºå®šä½æ•°æ®æ–‡ä»¶
    'data/file_index': 0,       # ç”¨äºå®šä½æ•°æ®æ–‡ä»¶
    'dataset_from_index': 0,
    'dataset_to_index': 25,
    'length': 26,
    'tasks': ['task description'],
}
```

### æ•°æ®å¸§å¿…éœ€å­—æ®µ

æ¯ä¸ª parquet æ–‡ä»¶ä¸­çš„æ¯ä¸€å¸§ï¼š

```python
{
    # è§‚æµ‹æ•°æ®
    'observation.images.image': tensor([3, 256, 256]),
    'observation.images.image2': tensor([3, 256, 256]),
    'observation.state': tensor([8]),
    
    # åŠ¨ä½œæ•°æ®
    'action': tensor([7]),
    'timestamp': float,
    
    # å…ƒæ•°æ®ï¼ˆå¿…éœ€ï¼‰
    'episode_index': int,   # æ‰€å±episodeçš„ç´¢å¼•
    'frame_index': int,     # Episodeå†…çš„å¸§ç´¢å¼•ï¼ˆ0-basedï¼‰
    'index': int,           # å…¨å±€å¸§ç´¢å¼•
    'task_index': int,      # ä»»åŠ¡ç´¢å¼•
}
```

### tasks.parquet æ ¼å¼è¦æ±‚

```python
# âœ… æ­£ç¡®ï¼šä»»åŠ¡æè¿°ä½œä¸º DataFrame çš„ index
                            task_index
task                                  
pick up the white                    0
put the white on the left            1

# âŒ é”™è¯¯ï¼šä»»åŠ¡æè¿°ä½œä¸ºåˆ—
   task_index                  task
0           0     pick up the white
1           1  put the white on the left
```

---

## ä¿®å¤çš„æ–‡ä»¶

æ‰€æœ‰ä¿®å¤éƒ½åœ¨ `dataset_cutter.py` æ–‡ä»¶ä¸­ï¼š

1. **ç¬¬262-272è¡Œ**: æ·»åŠ ä»»åŠ¡æ˜ å°„æ„å»ºé€»è¾‘
2. **ç¬¬288-305è¡Œ**: æ·»åŠ  `data/chunk_index` å’Œ `data/file_index`
3. **ç¬¬310-324è¡Œ**: å¼ºåˆ¶è¦†ç›– episode_index å’Œ task_index
4. **ç¬¬368-374è¡Œ**: ä¿®å¤ tasks.parquet æ ¼å¼
5. **ç¬¬407-420è¡Œ**: ä¿å­˜å…ƒæ•°æ®å­—æ®µåˆ° parquet
6. **ç¬¬415-427è¡Œ**: å®šä¹‰å…ƒæ•°æ®å­—æ®µç±»å‹
7. **ç¬¬447-519è¡Œ**: ç”Ÿæˆå®Œæ•´çš„ info.json
8. **ç¬¬468è¡Œ**: ä¿®æ­£ data_path æ¨¡æ¿

---

## ä½¿ç”¨æ–¹æ³•

### ç”Ÿæˆæ–°æ•°æ®é›†

```bash
cd /home/dongyingyibadao/data_dealer_auto

# åˆ é™¤æ—§æ•°æ®é›†
rm -rf cut_dataset

# ç”Ÿæˆæ–°æ•°æ®é›†ï¼ˆæœ¬åœ°æ¨¡å¼ï¼‰
python auto_cut_dataset.py \
    --end-idx 600 \
    --before-frames 15 \
    --after-frames 10 \
    --llm-provider local \
    --save-mode lerobot \
    --max-episodes 15

# æˆ–ä½¿ç”¨ GPT æ¨¡å¼ï¼ˆéœ€è¦ API Keyï¼‰
python auto_cut_dataset.py \
    --end-idx 600 \
    --before-frames 15 \
    --after-frames 10 \
    --llm-provider gpt \
    --llm-api-key "your-key" \
    --llm-api-base "https://gpt.yunstorm.com/" \
    --llm-api-version "2025-01-01-preview" \
    --llm-model "gpt-4o" \
    --save-mode lerobot \
    --max-episodes 15
```

### éªŒè¯æ•°æ®é›†

```python
from lerobot.datasets.lerobot_dataset import LeRobotDataset

# åŠ è½½æ•°æ®é›†
ds = LeRobotDataset('cut_dataset', root='/path/to/cut_dataset')

# æ£€æŸ¥åŸºæœ¬ä¿¡æ¯
print(f"æ€»å¸§æ•°: {len(ds)}")
print(f"Episodes: {ds.num_episodes}")

# æ£€æŸ¥ episode_index
unique_eps = sorted(ds.hf_dataset.unique('episode_index'))
print(f"å”¯ä¸€çš„ episode_index: {unique_eps}")

# æ£€æŸ¥ task_index å’Œ task
for ep_idx in range(min(5, ds.num_episodes)):
    frame = ds[ds.meta.episodes[ep_idx]['dataset_from_index']]
    print(f"Episode {ep_idx}:")
    print(f"  task_index: {frame['task_index'].item()}")
    print(f"  task: {frame['task']}")
```

---

## ç›¸å…³æ–‡æ¡£

- **æœ¬æ–‡æ¡£**: å®Œæ•´ä¿®å¤æ€»ç»“
- **README.md**: é¡¹ç›®ä¸»æ–‡æ¡£
- **docs/USAGE_GUIDE.md**: è¯¦ç»†ä½¿ç”¨æŒ‡å—
- **docs/QUICK_START.md**: å¿«é€Ÿå¼€å§‹æ•™ç¨‹

---

**ä¿®å¤æ—¥æœŸ**: 2024å¹´12æœˆ8æ—¥

**ä¿®å¤äººå‘˜**: GitHub Copilot AI Assistant

**éªŒè¯çŠ¶æ€**: âœ… æ‰€æœ‰ä¿®å¤å·²éªŒè¯é€šè¿‡
